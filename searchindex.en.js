var relearn_searchindex = [
  {
    "breadcrumb": "Go Kure \u003e Concepts",
    "content": "Kure Architecture Documentation Version: 2.0.0\nDate: August 2025\nStatus: Complete\nExecutive Summary Kure is a Go library for programmatically building Kubernetes resources used by GitOps tools (Flux, cert-manager, MetalLB, External Secrets). The library emphasizes strongly-typed object construction over templating engines, providing a composable, type-safe approach to generating Kubernetes manifests.\nKey Architectural Achievements:\nDomain-Driven Design: Hierarchical cluster model with clear boundaries Interface Segregation: Split monolithic workflow interfaces into focused components Type Safety: Strong typing throughout with comprehensive validation GitOps Agnostic: Support for multiple GitOps tools through pluggable workflows Declarative Patching: JSONPath-based patching system with structure preservation The architecture supports complex Kubernetes cluster configurations while maintaining simplicity and extensibility through clean separation of concerns and well-defined interfaces.\nTable of Contents Architecture Overview Domain Model Architecture Workflow Architecture Error Handling Architecture Resource Builder Pattern Patch System Architecture Layout and Packaging Naming Conventions Developer Guidelines Performance Characteristics Security Model Testing Architecture Appendices Architecture Overview System Boundaries Kure operates within the Kubernetes ecosystem as a library for programmatic resource generation:\ngraph TB subgraph \"Kure Library\" DM[Domain Model] WF[Workflow Engines] RB[Resource Builders] PS[Patch System] LO[Layout Engine] end subgraph \"GitOps Tools\" FLUX[Flux] ARGO[ArgoCD] end subgraph \"Kubernetes\" K8S[Core Resources] CRD[Custom Resources] end USER[User Code] --\u003e DM DM --\u003e WF WF --\u003e RB RB --\u003e K8S RB --\u003e CRD WF --\u003e LO LO --\u003e FLUX LO --\u003e ARGO PS --\u003e K8S Core Components The system is organized around four primary architectural layers:\nDomain Model (pkg/stack/): Hierarchical abstractions for cluster configuration Workflow Engines (pkg/stack/workflow.go, pkg/stack/fluxcd/, pkg/stack/argocd/): GitOps-specific implementations Resource Builders (internal/): Strongly-typed Kubernetes resource factories Support Systems: Error handling, patching, layout, and I/O utilities Key Design Principles 1. Composition Over Inheritance\nDomain objects compose behavior through interfaces Workflow engines compose specialized generators Resources built through functional composition 2. Interface Segregation\nSmall, focused interfaces for specific concerns Workflow interfaces split by responsibility Clear separation between resource generation and layout 3. Immutable Constructs\nBuilder pattern creates immutable objects Patching creates new instances rather than modifying Functional approach to resource transformation 4. Type Safety\nStrong typing for all Kubernetes resources Compile-time validation of resource construction Custom error types with contextual information Domain Model Architecture Hierarchical Structure The domain model follows a four-tier hierarchy designed to mirror real-world Kubernetes cluster organization:\nCluster └── Node (Infrastructure/Applications) └── Bundle (Logical grouping) └── Application (Individual workloads) Cluster (pkg/stack/cluster.go) The root abstraction representing a complete Kubernetes cluster configuration:\ntype Cluster struct { Name string `yaml:\"name\"` Node *Node `yaml:\"node,omitempty\"` GitOps *GitOpsConfig `yaml:\"gitops,omitempty\"` } Design Decisions:\nSingle root node simplifies tree traversal GitOps configuration at cluster level for global policies Name field provides unique identification across environments Node (pkg/stack/cluster.go:47-64) Hierarchical containers for organizing related bundles:\ntype Node struct { Name string `yaml:\"name\"` ParentPath string `yaml:\"parentPath,omitempty\"` Children []*Node `yaml:\"children,omitempty\"` PackageRef *schema.GroupVersionKind `yaml:\"packageref,omitempty\"` Bundle *Bundle `yaml:\"bundle,omitempty\"` // Runtime fields (not serialized) parent *Node `yaml:\"-\"` pathMap map[string]*Node `yaml:\"-\"` } Anti-Circular Reference Design:\nParentPath string instead of direct parent pointer in serialized form Runtime parent field populated during InitializePathMap() Enables serialization while maintaining navigation efficiency Bundle (pkg/stack/bundle.go) Deployment units typically corresponding to single GitOps resources:\ntype Bundle struct { Name string `yaml:\"name\"` ParentPath string `yaml:\"parentPath,omitempty\"` DependsOn []*Bundle `yaml:\"dependsOn,omitempty\"` Applications []*Application `yaml:\"applications\"` SourceRef *SourceRef `yaml:\"sourceRef,omitempty\"` } Application (pkg/stack/application.go) Individual Kubernetes workloads or resource collections:\ntype Application struct { Name string `yaml:\"name\"` Resources []client.Object `yaml:\"resources\"` Labels map[string]string `yaml:\"labels,omitempty\"` } Hierarchy Navigation The domain model implements efficient tree traversal through a dual approach:\n1. Path-Based Navigation\nfunc (n *Node) GetPath() string { if n.ParentPath == \"\" { return n.Name } return n.ParentPath + \"/\" + n.Name } 2. Runtime Parent References\nfunc (n *Node) InitializePathMap() { pathMap := make(map[string]*Node) n.buildPathMap(pathMap, \"\") n.setPathMapRecursive(pathMap) } This design enables:\nEfficient serialization without circular references Fast runtime navigation through cached parent pointers Path-based lookups for configuration references Workflow Architecture Interface Segregation Pattern The workflow architecture implements Interface Segregation Principle by splitting monolithic interfaces into focused components:\n// pkg/stack/workflow.go type ResourceGenerator interface { GenerateFromCluster(*stack.Cluster) ([]client.Object, error) GenerateFromNode(*stack.Node) ([]client.Object, error) GenerateFromBundle(*stack.Bundle) ([]client.Object, error) } type LayoutIntegrator interface { IntegrateWithLayout(*layout.ManifestLayout, *stack.Cluster, layout.LayoutRules) error CreateLayoutWithResources(*stack.Cluster, layout.LayoutRules) (*layout.ManifestLayout, error) } type BootstrapGenerator interface { GenerateBootstrap(*stack.BootstrapConfig, *stack.Node) ([]client.Object, error) SupportedBootstrapModes() []string } type WorkflowEngine interface { ResourceGenerator LayoutIntegrator BootstrapGenerator GetName() string GetVersion() string } FluxCD Implementation The FluxCD workflow engine demonstrates the composition pattern:\n// pkg/stack/fluxcd/workflow_engine.go type WorkflowEngine struct { ResourceGen *ResourceGenerator // Pure resource generation LayoutInteg *LayoutIntegrator // Layout integration BootstrapGen *BootstrapGenerator // Bootstrap concerns } func NewWorkflowEngine() *WorkflowEngine { resourceGen := NewResourceGenerator() layoutInteg := NewLayoutIntegrator(resourceGen) bootstrapGen := NewBootstrapGenerator() return \u0026WorkflowEngine{ ResourceGen: resourceGen, LayoutInteg: layoutInteg, BootstrapGen: bootstrapGen, } } Component Responsibilities ResourceGenerator (pkg/stack/fluxcd/resource_generator.go)\nPure resource generation from domain objects Kustomization creation with proper source references Dependency management between bundles No layout or file system concerns LayoutIntegrator (pkg/stack/fluxcd/layout_integrator.go)\nIntegration with manifest layout system Directory structure generation File placement policies GitOps-specific layout requirements BootstrapGenerator (pkg/stack/fluxcd/bootstrap_generator.go)\nBootstrap resource generation GitOps system initialization Mode-specific configurations (gitops-toolkit vs flux-operator) Extensibility Pattern Adding new GitOps workflows follows a clear pattern:\nImplement Core Interfaces: ResourceGenerator, LayoutIntegrator, BootstrapGenerator Compose WorkflowEngine: Combine specialized generators Register with Layout: Add layout rules for the new workflow Provide Public API: Create user-facing convenience functions Error Handling Architecture KureError System Kure implements a sophisticated error handling system based on typed errors with contextual information:\n// pkg/errors/errors.go type KureError interface { error Type() ErrorType Suggestion() string Context() map[string]interface{} } type ErrorType string const ( ErrorTypeValidation ErrorType = \"validation\" ErrorTypeResource ErrorType = \"resource\" ErrorTypePatch ErrorType = \"patch\" ErrorTypeParse ErrorType = \"parse\" ErrorTypeFile ErrorType = \"file\" ErrorTypeConfiguration ErrorType = \"configuration\" ErrorTypeInternal ErrorType = \"internal\" ) Error Type Architecture ValidationError (pkg/errors/errors.go:155-185)\nField-level validation failures Provides valid value suggestions Component context for debugging ResourceError (pkg/errors/errors.go:188-250)\nResource-specific errors (not found, validation failed) Includes resource type, name, and namespace Lists available alternatives when applicable PatchError (pkg/errors/errors.go:253-294)\nPatch operation failures Path and operation context Graceful degradation suggestions ParseError (pkg/errors/errors.go:297-340)\nFile parsing errors with location information Line and column numbers Format-specific help suggestions Centralized Validation The validation system provides consistent error reporting across all resource builders:\n// internal/validation/validators.go type Validator struct{} func (v *Validator) ValidateDeployment(deployment *appsv1.Deployment) error { return v.validateNotNil(deployment, errors.ErrNilDeployment) } // Pre-defined error instances for common cases var ( ErrNilDeployment = ResourceValidationError(\"Deployment\", \"\", \"deployment\", \"deployment cannot be nil\", nil) ErrNilPod = ResourceValidationError(\"Pod\", \"\", \"pod\", \"pod cannot be nil\", nil) // ... more predefined errors ) Error Wrapping Strategy Kure follows Go’s error wrapping conventions while adding structured context:\nfunc (we *WorkflowEngine) GenerateFromCluster(c *stack.Cluster) ([]client.Object, error) { if c == nil { return nil, errors.ResourceValidationError(\"Cluster\", \"\", \"cluster\", \"cluster cannot be nil\", nil) } resources, err := we.ResourceGen.GenerateFromCluster(c) if err != nil { return nil, errors.Wrapf(err, \"failed to generate resources for cluster %s\", c.Name) } return resources, nil } Resource Builder Pattern Builder Architecture Resource builders follow a consistent functional pattern across all Kubernetes resource types:\n// Pattern: Create* functions for constructors func CreateDeployment(name, namespace string) *appsv1.Deployment // Pattern: Add* functions for collection modifications func AddDeploymentContainer(deployment *appsv1.Deployment, container *corev1.Container) error // Pattern: Set* functions for field assignments func SetDeploymentReplicas(deployment *appsv1.Deployment, replicas int32) error Implementation Structure Each resource builder package (internal/kubernetes/, internal/fluxcd/, etc.) follows consistent organization:\ninternal/kubernetes/ ├── doc.go # Package documentation ├── deployment.go # Deployment builders ├── deployment_test.go # Deployment tests ├── service.go # Service builders ├── service_test.go # Service tests └── ... Type Safety Guarantees Builders provide compile-time type safety through:\nStrong Return Types: All constructors return specific Kubernetes types Validation Integration: Automatic validation in constructor functions Error Propagation: Explicit error returns for validation failures Example implementation:\n// internal/kubernetes/deployment.go func CreateDeployment(name, namespace string) *appsv1.Deployment { return \u0026appsv1.Deployment{ ObjectMeta: metav1.ObjectMeta{ Name: name, Namespace: namespace, }, Spec: appsv1.DeploymentSpec{ Selector: \u0026metav1.LabelSelector{ MatchLabels: map[string]string{ \"app\": name, }, }, Template: corev1.PodTemplateSpec{ ObjectMeta: metav1.ObjectMeta{ Labels: map[string]string{ \"app\": name, }, }, Spec: corev1.PodSpec{ Containers: []corev1.Container{}, }, }, }, } } func AddDeploymentContainer(deployment *appsv1.Deployment, container *corev1.Container) error { validator := validation.NewValidator() if err := validator.ValidateDeployment(deployment); err != nil { return err } if err := validator.ValidateContainer(container); err != nil { return err } deployment.Spec.Template.Spec.Containers = append( deployment.Spec.Template.Spec.Containers, *container) return nil } Cross-Resource Consistency All builders maintain consistency through:\nCommon Validation: Centralized validator used across all builders Standard Error Types: Consistent error reporting patterns Naming Conventions: Uniform function naming across resource types Patch System Architecture Design Philosophy The patch system implements declarative, JSONPath-based patching with structure preservation:\nOriginal YAML + Patch Declarations → Modified YAML (preserving comments/formatting) Patch File Format Patches use a TOML-inspired format (.kpatch files) that’s optimized for Kubernetes resources:\n# examples/patches/resources.kpatch [deployment.app] replicas: 3 [deployment.app.containers.name=main] image.repository: ghcr.io/example/app image.tag: \"${values.version}\" resources.requests.cpu: 250m [service.app.ports.name=http] port: 80 Path Resolution Engine The patch engine implements sophisticated path resolution:\n// pkg/patch/apply.go type PatchEngine struct { preserveStructure bool variables map[string]interface{} } func (pe *PatchEngine) Apply(yamlContent []byte, patchContent []byte) ([]byte, error) { // 1. Parse YAML with structure preservation // 2. Parse patch declarations // 3. Resolve JSONPaths with type inference // 4. Apply modifications preserving formatting // 5. Return modified YAML } List Selector System Advanced list manipulation through selector syntax:\nSelector Type Example Operation By index spec.containers.0 Replace at index 0 By key-value spec.containers.name=main Replace item with name=main Insert before spec.containers.-3 Insert before index 3 Insert after spec.containers.+2 Insert after index 2 Append to list spec.containers.- Append to end Variable Substitution The patch system supports typed variable substitution:\n[deployment.app] enabled: ${features.web_enabled} # Boolean feature flags replicas: ${values.replica_count} # Numeric values [service.app] hostname: \"${values.name}.${values.domain}\" # String interpolation Type Inference Patches automatically infer Kubernetes field types:\nResource field types from OpenAPI schema List element types from existing content Scalar types from variable context Layout and Packaging Layout Architecture The layout system manages directory structure and manifest organization:\n// pkg/stack/layout/types.go type ManifestLayout struct { Root string // Repository root path Clusters map[string]*ClusterLayout // Per-cluster layouts Global *GlobalLayout // Shared resources } type LayoutRules struct { BundleGrouping GroupingStrategy // How to group bundles ApplicationGrouping GroupingStrategy // How to group applications KustomizationMode KustomizationMode // Kustomization generation } Grouping Strategies GroupFlat: Each item gets its own directory\nclusters/prod/ ├── bundles/ │ ├── monitoring/ │ ├── logging/ │ └── ingress/ └── apps/ ├── frontend/ ├── backend/ └── database/ GroupByParent: Items grouped under parent directories\nclusters/prod/ ├── infrastructure/ │ ├── monitoring/ │ ├── logging/ │ └── ingress/ └── applications/ ├── frontend/ ├── backend/ └── database/ GitOps Integration Layout integrates with GitOps tools through specialized placement:\nFlux Placement (pkg/stack/layout/config.go)\nKustomization resources placed in flux-system namespace Source references use relative paths (./clusters/prod/...) Automatic kustomization.yaml generation ArgoCD Placement\nApplication resources in argocd namespace Source paths without ./ prefix Manual kustomization.yaml required Directory Structure Generation // pkg/stack/layout/walker.go func WalkCluster(cluster *stack.Cluster, rules LayoutRules) (*ManifestLayout, error) { layout := \u0026ManifestLayout{ Root: \".\", Clusters: make(map[string]*ClusterLayout), } clusterLayout := \u0026ClusterLayout{ Name: cluster.Name, Path: filepath.Join(\"clusters\", cluster.Name), } // Walk node hierarchy if err := walkNode(cluster.Node, clusterLayout, rules); err != nil { return nil, err } layout.Clusters[cluster.Name] = clusterLayout return layout, nil } Naming Conventions Function Naming Standards Kure follows strict naming conventions based on function purpose:\nConstructor Functions // Go type constructors use New* prefix func NewCluster(name string, tree *Node) *Cluster func NewBundle(name string, resources []*Application, labels map[string]string) (*Bundle, error) // Kubernetes resource factories use descriptive names func CreateDeployment(name, namespace string) *appsv1.Deployment func CreateService(name, namespace string) *corev1.Service Helper Functions // Adders for collection modifications func AddDeploymentContainer(deployment *appsv1.Deployment, container *corev1.Container) error func AddServicePort(service *corev1.Service, port corev1.ServicePort) error // Setters for field assignments func SetDeploymentReplicas(deployment *appsv1.Deployment, replicas int32) error func SetServiceType(service *corev1.Service, serviceType corev1.ServiceType) error Workflow Functions // Engine constructors follow New* pattern func NewWorkflowEngine() *WorkflowEngine func NewResourceGenerator() *ResourceGenerator // Public APIs use descriptive names func Engine() *WorkflowEngine // Default engine func EngineWithMode(mode layout.KustomizationMode) *WorkflowEngine // Configured engine Package Organization Standards pkg/ # Public APIs and interfaces ├── stack/ # Domain model (public) │ ├── fluxcd/ # FluxCD workflow implementation │ ├── argocd/ # ArgoCD workflow implementation │ └── layout/ # Layout generation utilities ├── stack/workflow.go # Workflow interfaces (public) ├── errors/ # Error handling utilities (public) └── patch/ # Patch system (public) internal/ # Implementation packages (private) ├── kubernetes/ # Core Kubernetes builders ├── fluxcd/ # Flux resource builders ├── certmanager/ # cert-manager builders ├── metallb/ # MetalLB builders ├── externalsecrets/ # External Secrets builders └── validation/ # Centralized validation File Naming Patterns Implementation files: {resource_type}.go (e.g., deployment.go, service.go) Test files: {resource_type}_test.go (e.g., deployment_test.go) Documentation: doc.go for package documentation Design documents: DESIGN.md, README.md in relevant packages Developer Guidelines Adding New Resource Builders Follow this standardized process for adding Kubernetes resource support:\n1. Create Constructor Function // internal/kubernetes/newresource.go func CreateNewResource(name, namespace string, opts ...Option) *v1.NewResource { resource := \u0026v1.NewResource{ ObjectMeta: metav1.ObjectMeta{ Name: name, Namespace: namespace, }, Spec: v1.NewResourceSpec{ // Initialize required fields }, } // Apply options for _, opt := range opts { opt(resource) } return resource } 2. Add Helper Functions func AddNewResourceField(resource *v1.NewResource, field FieldType) error { validator := validation.NewValidator() if err := validator.ValidateNewResource(resource); err != nil { return err } if err := validator.ValidateField(field); err != nil { return err } // Add field to resource resource.Spec.Fields = append(resource.Spec.Fields, field) return nil } func SetNewResourceProperty(resource *v1.NewResource, value PropertyType) error { // Validation and assignment } 3. Add Validation Support // internal/validation/validators.go func (v *Validator) ValidateNewResource(resource *v1.NewResource) error { return v.validateNotNil(resource, errors.ErrNilNewResource) } // pkg/errors/errors.go - Add to predefined errors var ErrNilNewResource = ResourceValidationError(\"NewResource\", \"\", \"newresource\", \"new resource cannot be nil\", nil) 4. Comprehensive Testing // internal/kubernetes/newresource_test.go func TestCreateNewResource(t *testing.T) { resource := CreateNewResource(\"test\", \"default\") if resource == nil { t.Fatal(\"expected non-nil resource\") } // Validate required fields if resource.Name != \"test\" { t.Errorf(\"expected name 'test', got %s\", resource.Name) } if resource.Namespace != \"default\" { t.Errorf(\"expected namespace 'default', got %s\", resource.Namespace) } } func TestNewResourceHelpers(t *testing.T) { resource := CreateNewResource(\"test\", \"default\") // Test all helper functions field := FieldType{/* valid field */} if err := AddNewResourceField(resource, field); err != nil { t.Errorf(\"unexpected error: %v\", err) } // Validate field was added if len(resource.Spec.Fields) != 1 { t.Errorf(\"expected 1 field, got %d\", len(resource.Spec.Fields)) } } Extending Domain Model When extending the core domain model:\n1. Maintain Hierarchy Consistency // Add new domain types following existing patterns type NewDomainType struct { Name string `yaml:\"name\"` ParentPath string `yaml:\"parentPath,omitempty\"` // Domain-specific fields // Runtime navigation (not serialized) parent *ParentType `yaml:\"-\"` pathMap map[string]*NewType `yaml:\"-\"` } 2. Implement Navigation Methods func (n *NewDomainType) SetParent(parent *ParentType) { n.parent = parent if parent == nil { n.ParentPath = \"\" } else { n.ParentPath = parent.GetPath() } } func (n *NewDomainType) GetPath() string { if n.ParentPath == \"\" { return n.Name } return n.ParentPath + \"/\" + n.Name } 3. Update Workflow Implementations Ensure all workflow engines handle the new domain type appropriately.\nImplementing New GitOps Workflows To add support for new GitOps tools:\n1. Implement Core Interfaces // pkg/stack/newtool/resource_generator.go type ResourceGenerator struct { // Tool-specific configuration } func (rg *ResourceGenerator) GenerateFromCluster(c *stack.Cluster) ([]client.Object, error) { // Tool-specific resource generation } // Implement other ResourceGenerator methods 2. Create Layout Integration // pkg/stack/newtool/layout_integrator.go type LayoutIntegrator struct { ResourceGen *ResourceGenerator // Tool-specific layout configuration } func (li *LayoutIntegrator) IntegrateWithLayout(ml *layout.ManifestLayout, c *stack.Cluster, rules layout.LayoutRules) error { // Tool-specific layout integration } 3. Compose Workflow Engine // pkg/stack/newtool/workflow_engine.go type WorkflowEngine struct { ResourceGen *ResourceGenerator LayoutInteg *LayoutIntegrator BootstrapGen *BootstrapGenerator } func NewWorkflowEngine() *WorkflowEngine { // Compose components } // Implement workflow.WorkflowEngine interface 4. Add Public API // pkg/stack/newtool/newtool.go func Engine() *WorkflowEngine { return NewWorkflowEngine() } Testing Patterns Kure maintains comprehensive test coverage through consistent patterns:\nUnit Testing func TestResourceCreation(t *testing.T) { // Test constructor resource := CreateResource(\"test\", \"default\") // Validate required fields // Test error conditions // Verify helper functions } func TestResourceValidation(t *testing.T) { // Test validation logic // Test error cases // Verify error messages } Integration Testing func TestWorkflowGeneration(t *testing.T) { // Create domain model cluster := stack.NewCluster(\"test\", rootNode) // Generate with workflow engine := fluxcd.Engine() resources, err := engine.GenerateFromCluster(cluster) // Validate generated resources // Test layout integration } Error Testing func TestErrorHandling(t *testing.T) { // Test nil inputs err := AddResourceField(nil, field) if !errors.IsType(err, errors.ErrorTypeValidation) { t.Errorf(\"expected validation error, got %T\", err) } // Test error context kureErr := errors.GetKureError(err) if kureErr == nil { t.Error(\"expected KureError\") } } Performance Characteristics Resource Generation Performance Kure is optimized for batch resource generation rather than individual operations:\nBenchmarks (typical 100-node cluster):\nDomain model creation: ~1ms Resource generation: ~10ms Layout generation: ~5ms YAML serialization: ~15ms Memory Usage:\nDomain model: ~100KB per 100 resources Generated resources: ~1MB per 1000 resources Layout structures: ~50KB per cluster Optimization Strategies 1. Lazy Initialization func (n *Node) InitializePathMap() { // Only build path map when needed if n.pathMap == nil { pathMap := make(map[string]*Node) n.buildPathMap(pathMap, \"\") n.setPathMapRecursive(pathMap) } } 2. Resource Pooling // Reuse validation instances var validatorPool = sync.Pool{ New: func() interface{} { return validation.NewValidator() }, } 3. Batch Operations func (we *WorkflowEngine) GenerateFromCluster(c *stack.Cluster) ([]client.Object, error) { // Generate all resources in single pass // Minimize allocation overhead // Batch validation operations } Bottlenecks and Mitigations Known Bottlenecks:\nYAML serialization (mitigated by streaming output) Path resolution in complex hierarchies (mitigated by path caching) Validation overhead (mitigated by batch validation) Scaling Characteristics:\nLinear scaling with number of resources Logarithmic scaling with hierarchy depth Constant memory overhead per resource type Security Model Secret Management Kure follows Kubernetes security best practices for secret handling:\n1. No Hardcoded Secrets // NEVER do this func CreateSecretWithData(name, namespace, password string) *corev1.Secret { return \u0026corev1.Secret{ Data: map[string][]byte{ \"password\": []byte(password), // WRONG: hardcoded secret }, } } // CORRECT approach - reference existing secrets func CreateCertificateWithSecret(name, namespace string, secretRef cmmeta.SecretKeySelector) *cmv1.Certificate { return \u0026cmv1.Certificate{ Spec: cmv1.CertificateSpec{ SecretName: secretRef.Name, // Reference, don't embed }, } } 2. Secret Reference Pattern // Standard pattern for secret references key := cmmeta.SecretKeySelector{ LocalObjectReference: cmmeta.LocalObjectReference{Name: \"secret-name\"}, Key: \"key-name\", } // Use in resource builders cert := certmanager.CreateCertificate(\"tls-cert\", \"default\") certmanager.SetCertificateIssuerSecret(cert, key) RBAC Integration Resource builders provide granular RBAC control:\n// Create minimal privilege roles role := kubernetes.CreateRole(\"app-reader\", \"default\") kubernetes.AddRoleRule(role, rbacv1.PolicyRule{ APIGroups: []string{\"\"}, Resources: []string{\"pods\"}, Verbs: []string{\"get\", \"list\"}, }) // Bind to specific accounts binding := kubernetes.CreateRoleBinding(\"app-reader\", \"default\") kubernetes.SetRoleBindingRole(binding, \"app-reader\") kubernetes.AddRoleBindingSubject(binding, rbacv1.Subject{ Kind: \"ServiceAccount\", Name: \"app-sa\", }) Certificate Management cert-manager integration provides secure TLS:\n// ACME challenge configuration issuer := certmanager.CreateClusterIssuer(\"letsencrypt\") certmanager.SetClusterIssuerACME(issuer, \"https://acme-v02.api.letsencrypt.org/directory\") certmanager.AddClusterIssuerACMEDNS01Provider(issuer, \"cloudflare\", map[string]string{ \"email\": \"admin@example.com\", }) // Certificate with DNS validation cert := certmanager.CreateCertificate(\"api-tls\", \"default\") certmanager.SetCertificateIssuer(cert, cmmeta.ObjectReference{ Name: \"letsencrypt\", Kind: \"ClusterIssuer\", }) certmanager.AddCertificateDNSName(cert, \"api.example.com\") Input Validation All user inputs undergo strict validation:\nfunc CreateResource(name, namespace string) (*Resource, error) { // Validate Kubernetes naming conventions if !isValidKubernetesName(name) { return nil, errors.NewValidationError(\"name\", name, \"Resource\", []string{\"lowercase\", \"alphanumeric\", \"hyphens-only\"}) } // Validate namespace format if namespace != \"\" \u0026\u0026 !isValidNamespace(namespace) { return nil, errors.NewValidationError(\"namespace\", namespace, \"Resource\", []string{\"valid-namespace-name\"}) } return \u0026Resource{Name: name, Namespace: namespace}, nil } Testing Architecture Test Organization Kure maintains 105 test files with comprehensive coverage:\ninternal/ ├── kubernetes/ │ ├── deployment_test.go │ ├── service_test.go │ └── ... ├── fluxcd/ │ ├── kustomize_test.go │ ├── source_test.go │ └── ... └── ... pkg/ ├── stack/ │ ├── application_test.go │ ├── bundle_test.go │ └── ... ├── patch/ │ ├── apply_test.go │ ├── set_test.go │ └── ... └── ... Testing Patterns Constructor Testing func TestCreateDeployment(t *testing.T) { deployment := CreateDeployment(\"test-app\", \"default\") // Validate non-nil result if deployment == nil { t.Fatal(\"expected non-nil deployment\") } // Validate required fields if deployment.Name != \"test-app\" { t.Errorf(\"expected name 'test-app', got %s\", deployment.Name) } if deployment.Namespace != \"default\" { t.Errorf(\"expected namespace 'default', got %s\", deployment.Namespace) } // Validate default values if deployment.Spec.Replicas == nil || *deployment.Spec.Replicas != 1 { t.Error(\"expected default replicas to be 1\") } } Helper Function Testing func TestAddDeploymentContainer(t *testing.T) { deployment := CreateDeployment(\"test-app\", \"default\") container := \u0026corev1.Container{ Name: \"main\", Image: \"nginx:latest\", } // Test successful addition err := AddDeploymentContainer(deployment, container) if err != nil { t.Fatalf(\"unexpected error: %v\", err) } // Validate container was added if len(deployment.Spec.Template.Spec.Containers) != 1 { t.Errorf(\"expected 1 container, got %d\", len(deployment.Spec.Template.Spec.Containers)) } // Test error conditions err = AddDeploymentContainer(nil, container) if err == nil { t.Error(\"expected error for nil deployment\") } err = AddDeploymentContainer(deployment, nil) if err == nil { t.Error(\"expected error for nil container\") } } Workflow Testing func TestFluxWorkflowGeneration(t *testing.T) { // Create test cluster app := \u0026stack.Application{ Name: \"test-app\", Resources: []client.Object{ kubernetes.CreateDeployment(\"app\", \"default\"), }, } bundle := \u0026stack.Bundle{ Name: \"test-bundle\", Applications: []*stack.Application{app}, } node := \u0026stack.Node{ Name: \"test-node\", Bundle: bundle, } cluster := stack.NewCluster(\"test-cluster\", node) // Test resource generation engine := fluxcd.Engine() resources, err := engine.GenerateFromCluster(cluster) if err != nil { t.Fatalf(\"unexpected error: %v\", err) } if len(resources) == 0 { t.Error(\"expected generated resources\") } // Validate resource types hasKustomization := false for _, resource := range resources { if resource.GetObjectKind().GroupVersionKind().Kind == \"Kustomization\" { hasKustomization = true break } } if !hasKustomization { t.Error(\"expected Kustomization resource\") } } Error Testing func TestValidationErrors(t *testing.T) { // Test validation error structure err := validation.NewValidator().ValidateDeployment(nil) if err == nil { t.Fatal(\"expected validation error\") } // Test KureError interface kureErr := errors.GetKureError(err) if kureErr == nil { t.Fatal(\"expected KureError\") } // Validate error properties if kureErr.Type() != errors.ErrorTypeValidation { t.Errorf(\"expected validation error type, got %s\", kureErr.Type()) } suggestion := kureErr.Suggestion() if suggestion == \"\" { t.Error(\"expected non-empty suggestion\") } context := kureErr.Context() if context == nil { t.Error(\"expected error context\") } } Test Utilities Common test utilities for consistent testing:\n// Test helper functions func createTestCluster(name string) *stack.Cluster { // Standard test cluster creation } func validateResource(t *testing.T, resource client.Object, expectedKind string) { // Standard resource validation } func assertNoError(t *testing.T, err error) { if err != nil { t.Fatalf(\"unexpected error: %v\", err) } } func assertError(t *testing.T, err error, expectedType errors.ErrorType) { if err == nil { t.Fatal(\"expected error\") } if !errors.IsType(err, expectedType) { t.Errorf(\"expected error type %s, got %T\", expectedType, err) } } Appendices Appendix A: Glossary Application: Individual Kubernetes workload or resource collection within a Bundle.\nBundle: Deployment unit typically corresponding to a single GitOps resource (e.g., Flux Kustomization).\nCluster: Root abstraction representing a complete Kubernetes cluster configuration.\nDomain Model: The hierarchical structure (Cluster → Node → Bundle → Application) representing cluster organization.\nGitOps Engine: Implementation of GitOps-specific resource generation and layout integration.\nKureError: Structured error type providing contextual information and suggestions.\nLayout: Directory structure and manifest organization for GitOps repositories.\nNode: Hierarchical container for organizing related Bundles (e.g., infrastructure vs applications).\nPatch: Declarative modification of Kubernetes resources using JSONPath-based operations.\nResource Builder: Strongly-typed factory function for creating Kubernetes resources.\nWorkflow Engine: Complete GitOps workflow implementation combining resource generation, layout integration, and bootstrap capabilities.\nAppendix B: References Kubernetes API Reference Flux Documentation ArgoCD Documentation cert-manager Documentation MetalLB Documentation External Secrets Operator Appendix C: Design Documents Additional design documentation available in the repository:\npkg/patch/DESIGN.md: Detailed patch system specification pkg/patch/PATCH_ENGINE_DESIGN.md: Patch engine implementation details pkg/patch/PATH_RESOLUTION.md: JSONPath resolution algorithms pkg/stack/layout/README.md: Layout system overview pkg/stack/workflow.go: Workflow interface definitions Appendix D: Migration Guide For migrating from previous versions:\nV1 to V2 Migration Domain Model Changes:\nNode hierarchy now uses ParentPath strings instead of direct parent pointers Call InitializePathMap() on root nodes after construction Bundle hierarchy follows same pattern Workflow Interface Changes:\nSplit monolithic workflow interfaces into specialized components Update implementations to use ResourceGenerator, LayoutIntegrator, BootstrapGenerator Compose WorkflowEngine from specialized generators Error Handling Changes:\nReplace generic errors with typed KureError instances Use centralized validation from internal/validation package Handle error context and suggestions in error reporting Function Naming Changes:\nConstructor functions now follow New* vs Create* patterns consistently Update imports to use new package structure Helper function signatures remain compatible This comprehensive architecture serves as the foundation for Kure’s continued evolution while maintaining backward compatibility and extensibility.",
    "description": "Kure Architecture Documentation Version: 2.0.0\nDate: August 2025\nStatus: Complete\nExecutive Summary Kure is a Go library for programmatically building Kubernetes resources used by GitOps tools (Flux, cert-manager, MetalLB, External Secrets). The library emphasizes strongly-typed object construction over templating engines, providing a composable, type-safe approach to generating Kubernetes manifests.\nKey Architectural Achievements:\nDomain-Driven Design: Hierarchical cluster model with clear boundaries Interface Segregation: Split monolithic workflow interfaces into focused components Type Safety: Strong typing throughout with comprehensive validation GitOps Agnostic: Support for multiple GitOps tools through pluggable workflows Declarative Patching: JSONPath-based patching system with structure preservation The architecture supports complex Kubernetes cluster configurations while maintaining simplicity and extensibility through clean separation of concerns and well-defined interfaces.",
    "tags": [],
    "title": "Architecture",
    "uri": "/concepts/architecture/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Contributing",
    "content": "Development Guide This guide covers development workflows and tooling for the Kure project.\nQuick Start # Get help with all available commands make help # Run all standard development tasks make all # Quick development cycle make check Contributing Workflow The main branch is protected — all changes must go through pull requests.\nBranch Workflow Create a feature branch from main:\ngit checkout -b feat/my-feature main Use branch prefixes: feat/, fix/, docs/, chore/\nDevelop and test locally:\nmake check # Quick validation make precommit # Full pre-commit checks Push and create a pull request:\ngit push -u origin feat/my-feature gh pr create Fill out the PR template (.github/PULL_REQUEST_TEMPLATE.md).\nPass required CI checks: lint, test, build\nGet 1 approving review, resolve all conversations\nMerge (linear history required — rebase, no merge commits)\nBranch Protection Rules Enforced via the main-protection repository ruleset :\nRequired status checks (strict): lint, test, build, rebase-check Auto-rebase: open PRs are automatically rebased when main is updated (via auto-rebase.yml) Pull requests required: all changes must go through a PR Conversation resolution: all review threads must be resolved Linear history: enforced (rebase only, no merge commits) Force pushes: disabled Branch deletion: disabled Bypass actors: kure-release-bot (GitHub App) — allowed to push release commits directly Development Workflow 1. Initial Setup # Install dependencies make deps # Install development tools make tools 2. Development Cycle # Format code make fmt # Run quick checks (lint, vet, short tests) make check # Run all tests make test # Run tests with coverage make test-coverage 3. Building # Build all executables make build # Build specific executable make build-kure make build-kurel make build-demo # Build with race detection for debugging make build-race 4. Testing # Run all tests make test # Run tests with verbose output make test-verbose # Run tests with race detection make test-race # Run only short tests (good for quick feedback) make test-short # Run tests with coverage report make test-coverage # Run benchmark tests make test-benchmark # Run integration tests (when available) make test-integration 5. Code Quality # Run all linting make lint # Format code make fmt # Run go vet make vet # Tidy modules make tidy # Run Qodana static analysis (requires Docker) make qodana 6. Demo and Examples # Run comprehensive demo make demo # Run GVK generators demo make demo-gvk # Generate all examples (alias for demo) make examples 7. Package Operations # Build a kurel package make kurel-build PACKAGE_PATH=path/to/package # Show package information make kurel-info PACKAGE_PATH=path/to/package Pre-commit Workflow Before committing changes, run:\nmake precommit This will:\nFormat code with go fmt Tidy modules Run linters Run go vet Run all tests CI/CD Pipeline The project uses several GitHub Actions workflows:\nMain CI Pipeline (.github/workflows/ci.yml) Triggers: Push to main/develop, PRs Jobs: Test (unit, race, coverage) Lint and format check Build executables Generate demo outputs Integration tests (main branch only) Cross-platform builds Security scanning Dependency vulnerability checks Qodana Code Quality (.github/workflows/code_quality.yml) Triggers: Push, PRs Purpose: Static analysis with JetBrains Qodana Uses: make deps for setup Auto-Rebase (.github/workflows/auto-rebase.yml) Triggers: Push to main Purpose: Automatically rebases all open PRs targeting main Uses: peter-evans/rebase@v4 Excludes: Dependabot PRs (dependencies label), draft PRs Auth: Requires AUTO_REBASE_PAT secret (PAT needed to trigger CI on rebased branches) Create Release (.github/workflows/release-create.yml) Triggers: Manual (workflow_dispatch) Inputs: Release type (alpha/beta/rc/stable/bump), scope, dry-run Purpose: Creates release commits and tags on main, pushes atomically Auth: Uses GitHub App token (RELEASE_APP_ID + RELEASE_APP_PRIVATE_KEY); the kure-release-bot App is listed as a bypass actor in the main-protection repository ruleset, allowing it to push release commits directly to main Concurrency: Only one release at a time (release-create group) To create a release:\nGo to Actions \u003e “Create Release” \u003e Run workflow Select release type and optional scope Optionally enable dry-run for preview Click “Run workflow” The pushed tag triggers the release pipeline below.\nRelease Pipeline (.github/workflows/release.yml) Triggers: Version tags (v*.*.*) Jobs: Pre-release validation with make ci-coverage Release readiness check with make release-check Multi-platform build with make release-build GitHub release creation Go proxy refresh PR Checks (.github/workflows/pr-checks.yml) Triggers: PR events Jobs: Quick validation with make check Security and dependency checks Test coverage validation Changed files analysis Performance benchmarks (when labeled) Documentation validation Dependabot Management Handling PRs Use @dependabot commands in PR comments (not gh pr close):\nCommand Effect @dependabot close Close PR, prevent recreation @dependabot ignore this dependency Close PR, ignore dependency permanently @dependabot ignore this major version Ignore major version updates @dependabot ignore this minor version Ignore minor version updates @dependabot rebase Rebase the PR @dependabot recreate Recreate the PR from scratch Deferring Updates When an update requires a blocked dependency (e.g., newer Go version):\nComment @dependabot close with explanation and link to blocking issue Do not use gh pr close directly - Dependabot will recreate the PR Reference: GitHub Docs - Dependabot PR Commands Makefile Targets Reference Development help - Display help message all - Run all standard development tasks info - Display project information clean - Clean build artifacts and caches Dependencies deps - Download and tidy Go modules deps-upgrade - Upgrade all dependencies tools - Install development tools outdated - Check for outdated dependencies Building build - Build all executables build-kure - Build kure executable build-kurel - Build kurel executable build-demo - Build demo executable build-race - Build with race detection Testing test - Run all tests test-verbose - Run tests with verbose output test-race - Run tests with race detection test-short - Run short tests only test-coverage - Run tests with coverage report test-benchmark - Run benchmark tests test-integration - Run integration tests Code Quality lint - Run all linters lint-go - Run golangci-lint fmt - Format Go code vet - Run go vet tidy - Tidy modules qodana - Run Qodana static analysis CI/CD ci - Run CI pipeline tasks ci-coverage - Run CI with coverage ci-integration - Run CI with integration tests check - Quick code quality check precommit - Run all pre-commit checks Release release TYPE=\u003ctype\u003e - Preview release (dry-run); types: alpha, beta, rc, stable, bump release-check - Check if ready for release release-build - Build release artifacts for multiple platforms release-snapshot - Test GoReleaser locally (no tag, no publish) Utilities generate - Run go generate mod-graph - Display module dependency graph list-packages - List all packages demo* - Various demo commands Environment Variables Key environment variables the Makefile respects:\nGO - Go command (default: go) GOROOT - Go root directory VERSION - Version string for builds BUILD_DIR - Build output directory (default: bin) OUTPUT_DIR - Demo output directory (default: out) TEST_TIMEOUT - Test timeout (default: 30s) PACKAGE_PATH - Package path for kurel operations Development Tips Running Demos The demo system generates example YAML files showing Kure’s capabilities:\n# Run all demos make demo # Generated files appear in out/ directory ls -la out/ Testing Strategy Use make test-short for quick feedback during development Use make test-coverage to check coverage before PRs Use make test-race to catch concurrency issues Use make check for quick pre-commit validation Code Quality The CI pipeline enforces 80% test coverage All code must pass golangci-lint checks Code must be properly formatted with go fmt Modules must be tidy Performance Benchmark tests can be run with make test-benchmark PR checks include performance benchmarks when labeled with performance Build targets include optimized release builds with -s -w flags Troubleshooting Build Issues # Clean everything and rebuild make clean all # Check Go installation and environment make info Test Failures # Run tests with verbose output for more details make test-verbose # Run specific test go test -v ./pkg/specific/package -run TestSpecific Dependency Issues # Update dependencies make deps-upgrade # Check for outdated or vulnerable dependencies make outdated This development guide provides a comprehensive overview of the development workflow using the Makefile and CI/CD pipeline.\nDocumentation Updates When modifying a package’s public API, update documentation in the same PR:\nPackage README — Update the README.md in the package directory (e.g., pkg/stack/README.md) Guides — Check the reverse mapping in AGENTS.md for guides that reference the changed package CLI reference — Regenerated automatically by make docs-cli (no manual updates needed) To verify the docs site builds correctly:\n# Check all mounted files exist bash site/scripts/check-mounts.sh # Generate CLI reference + build site mise run site:build Crane Integration Kure is a dependency of the Crane project (~/src/autops/wharf/crane).\nRelationship Crane transforms OAM → Kure domain model → Kubernetes manifests Kure provides the domain model and manifest generation engine Both repos are co-developed with local replace directives Key Files Crane’s requirements: ~/src/autops/wharf/crane/PLAN.md Crane’s agent guide: ~/src/autops/wharf/crane/AGENTS.md When Making Changes Check if change affects Crane’s integration Keep public API (pkg/stack/) stable when possible Update Crane if breaking changes are necessary Test with go mod tidy in Crane to verify compatibility Go Workspaces Crane uses Go workspaces for local development. The workspace file lives in the parent directory:\n# From wharf/ directory go work init go work use ./crane ./kure This allows Crane to use your local Kure changes without pushing.\nBefore pushing Kure changes that Crane depends on:\nPush Kure changes first In Crane: GOWORK=off go get github.com/go-kure/kure@main Commit the updated go.mod/go.sum in Crane",
    "description": "Development Guide This guide covers development workflows and tooling for the Kure project.\nQuick Start # Get help with all available commands make help # Run all standard development tasks make all # Quick development cycle make check Contributing Workflow The main branch is protected — all changes must go through pull requests.\nBranch Workflow Create a feature branch from main:\ngit checkout -b feat/my-feature main Use branch prefixes: feat/, fix/, docs/, chore/",
    "tags": [],
    "title": "Development Guide",
    "uri": "/contributing/guide/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Getting Started with Kure Kure is primarily a Go library. You can also install its CLI tools for package management and code generation.\nUsing as a Library Add Kure to your Go project:\ngo get github.com/go-kure/kure Then import the packages you need:\nimport ( \"github.com/go-kure/kure/pkg/stack\" \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" \"github.com/go-kure/kure/pkg/io\" ) Installing CLI Tools # kure — main CLI for resource generation go install github.com/go-kure/kure/cmd/kure@latest # kurel — package system for reusable application bundles go install github.com/go-kure/kure/cmd/kurel@latest Verify the installation:\nkure version kurel version Next Steps Follow the Quickstart guide Read about the Domain Model and Design Philosophy Explore the Guides for common workflows Try the Examples",
    "description": "Getting Started with Kure Kure is primarily a Go library. You can also install its CLI tools for package management and code generation.\nUsing as a Library Add Kure to your Go project:\ngo get github.com/go-kure/kure Then import the packages you need:\nimport ( \"github.com/go-kure/kure/pkg/stack\" \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" \"github.com/go-kure/kure/pkg/io\" ) Installing CLI Tools # kure — main CLI for resource generation go install github.com/go-kure/kure/cmd/kure@latest # kurel — package system for reusable application bundles go install github.com/go-kure/kure/cmd/kurel@latest Verify the installation:",
    "tags": [],
    "title": "Getting Started",
    "uri": "/getting-started/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Examples",
    "content": "Kure Patch Module Examples (TOML Format) This directory demonstrates the new TOML-style patch system with cert-manager as an example.\nFiles cert-manager-simple.yaml - Base cert-manager resources (simplified) resources.kpatch - Resource limits using TOML container selectors ingress.kpatch - Service configuration with port selectors security.kpatch - Security contexts with deployment targeting advanced.kpatch - Complex selectors and variable substitution Running the Demo go run ./cmd/demo -patches TOML Patch Format The patch files now use TOML-style headers for precise resource targeting:\n# Basic resource targeting [deployment.app] spec.replicas: 3 metadata.labels.env: production # Container-specific patches [deployment.app.containers.name=main] resources.requests.cpu: 100m resources.limits.memory: 512Mi # Service port configuration [service.app.ports.name=https] port: 443 nodePort: 30443 # Array index targeting [ingress.web.rules.0.paths.0] path: /api pathType: Prefix Header Grammar The TOML header format follows this grammar:\n[kind.name[.section[.subsection[.selector]]]] Selector Types Key-value selectors: containers.name=main Index selectors: ports.0, rules.1 Bracketed selectors: containers[image=nginx] Kubernetes Path Mapping The system intelligently maps TOML sections to Kubernetes paths:\nTOML Section Kubernetes Path (Deployment) Kubernetes Path (Service) containers spec.template.spec.containers spec.containers ports spec.template.spec.containers.ports spec.ports volumes spec.template.spec.volumes spec.volumes env spec.template.spec.containers.env N/A Variable Substitution Support for dynamic values using variable substitution:\n[deployment.app.containers.name=main] image.tag: \"${values.version}\" resources.requests.cpu: \"${values.cpu_request}\" debug.enabled: \"${features.enable_debug}\" Variable context:\n\u0026patch.VariableContext{ Values: map[string]interface{}{ \"version\": \"1.20\", \"cpu_request\": \"100m\", }, Features: map[string]bool{ \"enable_debug\": true, }, } Examples by Complexity Basic Resource Targeting [deployment.cert-manager] spec.replicas: 3 metadata.labels.environment: production Container-Specific Configuration [deployment.cert-manager.containers.name=cert-manager-controller] resources.requests.cpu: 100m resources.limits.memory: 512Mi securityContext.readOnlyRootFilesystem: true Service Configuration [service.cert-manager-webhook.ports.name=https] port: 9443 nodePort: 30443 Complex Array Manipulation # Add new environment variable [deployment.app.containers.name=main.env[+]] name: DEBUG_MODE value: \"true\" # Add new volume mount [deployment.app.containers.name=main.volumeMounts[+]] name: config mountPath: /etc/config readOnly: true Key Features Intelligent Path Resolution - Automatic mapping based on resource kind Precise Targeting - Container-specific, port-specific, rule-specific patches Variable Substitution - Dynamic values with ${values.key} syntax Complex Selectors - Multiple ways to target list items Backward Compatibility - Still supports legacy YAML format Context Awareness - Different behavior for different resource types Migration from YAML Old YAML format:\n- target: cert-manager patch: spec.template.spec.containers[0].resources.requests.cpu: \"100m\" New TOML format:\n[deployment.cert-manager.containers.0] resources.requests.cpu: 100m Or with semantic selector:\n[deployment.cert-manager.containers.name=cert-manager-controller] resources.requests.cpu: 100m The TOML format provides better readability, more precise targeting, and eliminates the need for long JSONPath expressions.",
    "description": "Kure Patch Module Examples (TOML Format) This directory demonstrates the new TOML-style patch system with cert-manager as an example.\nFiles cert-manager-simple.yaml - Base cert-manager resources (simplified) resources.kpatch - Resource limits using TOML container selectors ingress.kpatch - Service configuration with port selectors security.kpatch - Security contexts with deployment targeting advanced.kpatch - Complex selectors and variable substitution Running the Demo go run ./cmd/demo -patches TOML Patch Format The patch files now use TOML-style headers for precise resource targeting:",
    "tags": [],
    "title": "Patches",
    "uri": "/examples/patches/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Getting Started",
    "content": "Quickstart Guide This guide walks you through installing Kure, generating your first cluster configuration, and deploying with Flux.\nInstallation Install the Kure CLI tools using Go:\ngo install github.com/go-kure/kure/cmd/kure@latest go install github.com/go-kure/kure/cmd/kurel@latest Verify the installation:\nkure version kurel version Hello World: Generate a Simple Cluster Config Create a minimal Go program that generates Kubernetes manifests:\npackage main import ( \"os\" \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" \"github.com/go-kure/kure/pkg/io\" kustv1 \"github.com/fluxcd/kustomize-controller/api/v1\" ) func main() { // Create a Flux Kustomization ks := fluxcd.NewKustomization(\u0026fluxcd.KustomizationConfig{ Name: \"hello-world\", Namespace: \"flux-system\", Interval: \"5m\", Path: \"./clusters/production\", SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"flux-system\", }, }) // Print YAML to stdout printer := io.NewYAMLPrinter() printer.PrintObj(ks, os.Stdout) } Run the program to see the generated YAML:\ngo run main.go Output:\napiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: hello-world namespace: flux-system spec: interval: 5m path: ./clusters/production prune: true sourceRef: kind: GitRepository name: flux-system Build a Kurel Package Kurel packages provide a structured way to define reusable Kubernetes applications. Try building the example Frigate package:\ncd examples/kurel/frigate kurel build . This generates Kubernetes manifests from the package definition. Inspect the package structure:\nfrigate/ kurel.yaml # Package metadata parameters.yaml # Configurable parameters resources/ # Base Kubernetes resources patches/ # Optional patches Validate a package before deployment:\nkurel validate . View package information:\nkurel info . Deploy with Flux Once you have generated manifests, deploy them using Flux:\nCommit the manifests to your Git repository git add clusters/ git commit -m \"Add hello-world kustomization\" git push Flux reconciles automatically If Flux is already watching your repository, it will automatically apply the new Kustomization. Check the status:\nflux get kustomizations Or trigger manually flux reconcile kustomization flux-system --with-source Next Steps Architecture: Read ARCHITECTURE.md for a deep dive into Kure’s design Examples: Explore the examples/ directory for more complex configurations API Reference: See the full API at pkg.go.dev Patching: Learn about declarative patching in the README CLI Reference: Run kure --help and kurel --help for all available commands",
    "description": "Quickstart Guide This guide walks you through installing Kure, generating your first cluster configuration, and deploying with Flux.\nInstallation Install the Kure CLI tools using Go:\ngo install github.com/go-kure/kure/cmd/kure@latest go install github.com/go-kure/kure/cmd/kurel@latest Verify the installation:\nkure version kurel version Hello World: Generate a Simple Cluster Config Create a minimal Go program that generates Kubernetes manifests:\npackage main import ( \"os\" \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" \"github.com/go-kure/kure/pkg/io\" kustv1 \"github.com/fluxcd/kustomize-controller/api/v1\" ) func main() { // Create a Flux Kustomization ks := fluxcd.NewKustomization(\u0026fluxcd.KustomizationConfig{ Name: \"hello-world\", Namespace: \"flux-system\", Interval: \"5m\", Path: \"./clusters/production\", SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"flux-system\", }, }) // Print YAML to stdout printer := io.NewYAMLPrinter() printer.PrintObj(ks, os.Stdout) } Run the program to see the generated YAML:",
    "tags": [],
    "title": "Quickstart",
    "uri": "/getting-started/quickstart/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Changelog",
    "content": "Changelog All notable changes to this project will be documented in this file.\n[0.1.0-beta.1] - 2026-02-17 Added Add strategic merge patch support with namespace-aware target resolution Documentation Update branch protection docs to reflect ruleset migration Fixed Add release notes extraction to release workflow Use tab-indented code block for YAML example in doc comment Guard unstructured fallback from list decode panics Release read lock before invoking converter callback Fix CI lint baseline and resolve pre-existing lint issues [0.1.0-beta.0] - 2026-02-17 Added Expose HPA helpers in pkg/kubernetes Expose PDB helpers in pkg/kubernetes Add deterministic YAML serialization option Expose Deployment, Service, Ingress helpers in pkg/kubernetes Expose CronJob helpers in pkg/kubernetes Add optional Validator interface for ApplicationConfig Add unstructured fallback for unknown GVKs Implement Generate() for stack pipeline integration Add comprehensive server-set field stripping (#196) Add kure init scaffolding command (#136) Rewrite fluent builders with immutable copy semantics (#139) Migrate release automation from semver.sh to CI-driven release.sh Changed Consolidate generator registries into pkg/stack (#179) Dependencies Bump sigs.k8s.io/kustomize/api in the k8s-ecosystem group Documentation Add implementation workflow checklist Document ApplicationConfig breaking change (#178) Release V0.1.0-alpha.4 V0.1.0-beta.0 [0.1.0-alpha.3] - 2026-02-12 Documentation Add changelog entry for v0.1.0-alpha.3 Fixed Install syft in release workflow for SBOM generation Release V0.1.0-alpha.3 [0.1.0-alpha.2] - 2026-02-12 Added Deterministic kustomization.yaml ordering Add missing Bundle fields (Prune, Wait, Timeout, etc.) Clean YAML output in EncodeObjectsToYAML by default Implement createSource() for OCIRepository/GitRepository Add WriteToTar(io.Writer) for in-memory layout generation Propagate Bundle.Labels to all generated resources Rename CI job names to match branch protection check names Add Hugo documentation site with CI/CD and mise tasks Add auto-rebase workflow and rebase-check job Build Improve release workflow security and reproducibility CI Add GitLab mirror push after all checks pass Add divergence detection and tag sync to GitLab mirror Dependencies Bump github.com/google/cel-go from 0.26.1 to 0.27.0 Documentation Archive completed PLAN.md to docs/history/ Streamline README as landing page with badges Use shields.io badge for Go Report Card Restructure site around user needs with code-synced READMEs Fixed Use git-cliff for changelog generation in release script Bump Go 1.24.12 → 1.24.13, add govulncheck summary to CI Use path-based matching in findLayoutNode() Anchor GO_VERSION patterns to avoid matching HUGO_VERSION Add rollup build gate job to satisfy branch protection check Release V0.1.0-alpha.2 [0.1.0-alpha.1] - 2026-01-30 Fixed Run tests directly in release workflow instead of checking CI status [0.1.0-alpha.0] - 2026-01-30 Added Add storageclass helpers Add kustomize helpers Add flux source helpers Add helpers Add fluxcd builders package Add layout grouping and app file mode Support file- and dir-per-application layouts Implement OCI artifact separation in layout system Implement GitOps bootstrap and refactor demo system to data-driven architecture Implement comprehensive Kubernetes printer wrappers in io module Modernize error handling with custom error types and standardization Implement professional Cobra CLI with comprehensive command structure Implement comprehensive structured error handling system Add shorthand flags for common CLI options across all commands Complete kurel package system design documentation Implement package loader with hybrid error handling Implement variable resolver with cycle detection Implement patch processor with dependency resolution Implement schema generation and validation for launcher Complete Phase 4 - schema generation and validation Complete Phase 5 - output builder and local extensions Implement Phase 6 - CLI command integration Implement Phase 7 - comprehensive integration tests Implement GVK-based ApplicationConfig generator system Implement GVK-based versioning for stack module structs Implement GVK-based versioning for stack module structs Add comprehensive Makefile and CI/CD pipeline Complete KurelPackage generator implementation Enable Kubernetes schema inclusion in kurel CLI Implement fluent builder pattern Phase 1 Implement comprehensive interval validation for GitOps configurations Add Go version management tools Add fast precommit target for git hooks Add PodDisruptionBudget builder Add HorizontalPodAutoscaler builder Add combined-output mode to kure patch Add –diff option to kure patch Build Update Go to 1.24.12 to fix govulncheck vulnerabilities Automate changelog generation with git-cliff CI Add GitHub Action to refresh Go proxy on main branch commits Enforce Go version consistency in PR checks Remove Qodana workflow due to licensing issues Fix security scan action to use official gosec action Remove gosec security scan (CodeQL provides coverage) Changed Loop over YAML prints Split appsets module Export ApplyPatch Register k8s schemes on demand Move pkg/layout to pkg/stack/layout for better organization Move pkg/fluxcd to pkg/k8s/fluxcd for better organization Yaml dir naming and proper marshalling Modernize errors package to follow Go best practices Modernize patch module with clean syntax and comprehensive tooling Rename cmd/patch to cmd/kure for better CLI naming Promote patch command from subcommand to top-level command Rename .patch files to .kpatch to avoid conflicts with diff patches Eliminate circular references in Node and Bundle structures Centralize validation logic across Kubernetes builders Standardize error handling to use KureError consistently Standardize function naming conventions across codebase Multi-CLI architecture and package naming standardization Implement clean workflow interface architecture Implement launcher base types with shared libraries Implement shared internal/gvk infrastructure Apply go fmt formatting to codebase Simplify Claude settings with symlink and expanded permissions Reorganize task files with numbered prefixes Migrate to GoReleaser v2 workflow Consolidate Makefile targets and enhance dev workflow Standardize validation patterns across packages Consolidate 4 GitHub workflows into 2 (ci.yml + release.yml) Consolidate 4 GitHub workflows into 2 (ci.yml + release.yml) Improve pkg/kubernetes testability and coverage Dependencies Align k8s.io/cli-runtime to v0.33.2 to match replace directive Bump tj-actions/changed-files Bump github.com/external-secrets/external-secrets Bump sigs.k8s.io/kustomize/api from 0.20.0 to 0.21.0 Bump sigs.k8s.io/yaml from 1.5.0 to 1.6.0 Implement centralized dependency version management Document blocked dependency updates for Go 1.25 Bump github.com/spf13/cobra in the go-safe group Bump github.com/cert-manager/cert-manager Update versions.yaml for cert-manager 1.16.5 Documentation Add project README Mention base resources and expose constructor Expand kio package documentation Expand kio documentation Expand fluxcd package overview Correct Flux auto-generated kustomization details Update README to reflect current repository state Add comprehensive architectural documentation Add comprehensive architectural documentation for generators Add comprehensive UX design document and recommendations Update project status and document remaining features Add comprehensive plugin architecture design Update CLAUDE.md with current project priorities and status Update CLAUDE.md with current project status and accurate metrics Update user documentation with current project state Add detailed explanation of CEL Validation Enhancement task Add comprehensive repository review and task management system Update task statuses after upstream rebase Add comprehensive puzl-cloud/kubesdk review with kure comparison Add task #1 for CEL validation enhancement Add workflow guidelines to tasks.md Remove references to non-existent demo-internals make target Add HPA and PDB builder tasks for Crane OAM support Add Crane integration documentation Add tasks README and update task 03 status Add quickstart guide Expand README with end-to-end examples Mark high-priority tasks 1-5, 23, 24 as completed Mark task #8 as completed Add comprehensive GoDoc documentation Mark task #10 as completed Mark task #6 as completed Mark tasks #7, #9, #11, #12 as completed Fixed Separate helper group comments Add missing unstructured import to patch CLI Correct type usage in generators package tests Resolve all layout module test failures Ensure all manifest directories have kustomization.yaml for GitOps compliance Resolve test failures in launcher module Resolve CLI test output capture issues Resolve all failing tests and improve TOML patch support Correct appworkload test to match ServiceConfig structure Update demo and kure commands to use new GVK-based ApplicationWrapper Resolve intermittent test failures in cmd/demo package Resolve stdout capture synchronization in demo tests Configure golangci-lint compatibility and resolve linting issues Correct YAML structure in CI workflow Add goimports to make fmt for CI/local parity Add GOPATH/bin to PATH in lint and fmt targets Upgrade Go to 1.24.11 to resolve security vulnerabilities Make max_depth_exceeded test deterministic Fix CVE in mapstructure and add workflow permissions Resolve repo issues across docs, CI, validation, and caching Propagate –strict flag to validator in kurel validate Update K8s compatibility matrix to test supported versions Remove K8s 0.33 from CI compatibility matrix Align mise.toml Go version with CI workflows Lower coverage threshold to 70% to match current main coverage Improve dependabot wildcard pattern matching in validation Block FluxCD major version updates in dependabot Testing Check errors Add runCluster coverage Add comprehensive test coverage for all packages Add comprehensive test coverage for FluxHelm internal package Skip demo integration tests in short mode Skip demo tests when examples directory is missing Fix data race in TestMainFunction Skip max_depth_exceeded test due to resolver bugs Add integration tests for stack generation workflows Add fuzz tests for patch parser Add Kubernetes version matrix to CI Add tests to improve coverage and fix Go version Add Phase 1 coverage for simple getters/setters Add Phase 2 parsing tests, reach 70.5% coverage Add Phase 3 validation tests, reach 100% validation coverage Add Phase 4 stack domain model tests Add Phase 5 layout integrator tests Add wrapper function tests, reach 94.8% gvk coverage Add setter function tests for internal packages Add comprehensive IO table and printer tests Add comprehensive appworkload internal tests Release V0.1.0-alpha.0",
    "description": "Changelog All notable changes to this project will be documented in this file.\n[0.1.0-beta.1] - 2026-02-17 Added Add strategic merge patch support with namespace-aware target resolution Documentation Update branch protection docs to reflect ruleset migration Fixed Add release notes extraction to release workflow Use tab-indented code block for YAML example in doc comment Guard unstructured fallback from list decode panics Release read lock before invoking converter callback Fix CI lint baseline and resolve pre-existing lint issues [0.1.0-beta.0] - 2026-02-17 Added Expose HPA helpers in pkg/kubernetes Expose PDB helpers in pkg/kubernetes Add deterministic YAML serialization option Expose Deployment, Service, Ingress helpers in pkg/kubernetes Expose CronJob helpers in pkg/kubernetes Add optional Validator interface for ApplicationConfig Add unstructured fallback for unknown GVKs Implement Generate() for stack pipeline integration Add comprehensive server-set field stripping (#196) Add kure init scaffolding command (#136) Rewrite fluent builders with immutable copy semantics (#139) Migrate release automation from semver.sh to CI-driven release.sh Changed Consolidate generator registries into pkg/stack (#179) Dependencies Bump sigs.k8s.io/kustomize/api in the k8s-ecosystem group Documentation Add implementation workflow checklist Document ApplicationConfig breaking change (#178) Release V0.1.0-alpha.4 V0.1.0-beta.0 [0.1.0-alpha.3] - 2026-02-12 Documentation Add changelog entry for v0.1.0-alpha.3 Fixed Install syft in release workflow for SBOM generation Release V0.1.0-alpha.3 [0.1.0-alpha.2] - 2026-02-12 Added Deterministic kustomization.yaml ordering Add missing Bundle fields (Prune, Wait, Timeout, etc.) Clean YAML output in EncodeObjectsToYAML by default Implement createSource() for OCIRepository/GitRepository Add WriteToTar(io.Writer) for in-memory layout generation Propagate Bundle.Labels to all generated resources Rename CI job names to match branch protection check names Add Hugo documentation site with CI/CD and mise tasks Add auto-rebase workflow and rebase-check job Build Improve release workflow security and reproducibility CI Add GitLab mirror push after all checks pass Add divergence detection and tag sync to GitLab mirror Dependencies Bump github.com/google/cel-go from 0.26.1 to 0.27.0 Documentation Archive completed PLAN.md to docs/history/ Streamline README as landing page with badges Use shields.io badge for Go Report Card Restructure site around user needs with code-synced READMEs Fixed Use git-cliff for changelog generation in release script Bump Go 1.24.12 → 1.24.13, add govulncheck summary to CI Use path-based matching in findLayoutNode() Anchor GO_VERSION patterns to avoid matching HUGO_VERSION Add rollup build gate job to satisfy branch protection check Release V0.1.0-alpha.2 [0.1.0-alpha.1] - 2026-01-30 Fixed Run tests directly in release workflow instead of checking CI status [0.1.0-alpha.0] - 2026-01-30 Added Add storageclass helpers Add kustomize helpers Add flux source helpers Add helpers Add fluxcd builders package Add layout grouping and app file mode Support file- and dir-per-application layouts Implement OCI artifact separation in layout system Implement GitOps bootstrap and refactor demo system to data-driven architecture Implement comprehensive Kubernetes printer wrappers in io module Modernize error handling with custom error types and standardization Implement professional Cobra CLI with comprehensive command structure Implement comprehensive structured error handling system Add shorthand flags for common CLI options across all commands Complete kurel package system design documentation Implement package loader with hybrid error handling Implement variable resolver with cycle detection Implement patch processor with dependency resolution Implement schema generation and validation for launcher Complete Phase 4 - schema generation and validation Complete Phase 5 - output builder and local extensions Implement Phase 6 - CLI command integration Implement Phase 7 - comprehensive integration tests Implement GVK-based ApplicationConfig generator system Implement GVK-based versioning for stack module structs Implement GVK-based versioning for stack module structs Add comprehensive Makefile and CI/CD pipeline Complete KurelPackage generator implementation Enable Kubernetes schema inclusion in kurel CLI Implement fluent builder pattern Phase 1 Implement comprehensive interval validation for GitOps configurations Add Go version management tools Add fast precommit target for git hooks Add PodDisruptionBudget builder Add HorizontalPodAutoscaler builder Add combined-output mode to kure patch Add –diff option to kure patch Build Update Go to 1.24.12 to fix govulncheck vulnerabilities Automate changelog generation with git-cliff CI Add GitHub Action to refresh Go proxy on main branch commits Enforce Go version consistency in PR checks Remove Qodana workflow due to licensing issues Fix security scan action to use official gosec action Remove gosec security scan (CodeQL provides coverage) Changed Loop over YAML prints Split appsets module Export ApplyPatch Register k8s schemes on demand Move pkg/layout to pkg/stack/layout for better organization Move pkg/fluxcd to pkg/k8s/fluxcd for better organization Yaml dir naming and proper marshalling Modernize errors package to follow Go best practices Modernize patch module with clean syntax and comprehensive tooling Rename cmd/patch to cmd/kure for better CLI naming Promote patch command from subcommand to top-level command Rename .patch files to .kpatch to avoid conflicts with diff patches Eliminate circular references in Node and Bundle structures Centralize validation logic across Kubernetes builders Standardize error handling to use KureError consistently Standardize function naming conventions across codebase Multi-CLI architecture and package naming standardization Implement clean workflow interface architecture Implement launcher base types with shared libraries Implement shared internal/gvk infrastructure Apply go fmt formatting to codebase Simplify Claude settings with symlink and expanded permissions Reorganize task files with numbered prefixes Migrate to GoReleaser v2 workflow Consolidate Makefile targets and enhance dev workflow Standardize validation patterns across packages Consolidate 4 GitHub workflows into 2 (ci.yml + release.yml) Consolidate 4 GitHub workflows into 2 (ci.yml + release.yml) Improve pkg/kubernetes testability and coverage Dependencies Align k8s.io/cli-runtime to v0.33.2 to match replace directive Bump tj-actions/changed-files Bump github.com/external-secrets/external-secrets Bump sigs.k8s.io/kustomize/api from 0.20.0 to 0.21.0 Bump sigs.k8s.io/yaml from 1.5.0 to 1.6.0 Implement centralized dependency version management Document blocked dependency updates for Go 1.25 Bump github.com/spf13/cobra in the go-safe group Bump github.com/cert-manager/cert-manager Update versions.yaml for cert-manager 1.16.5 Documentation Add project README Mention base resources and expose constructor Expand kio package documentation Expand kio documentation Expand fluxcd package overview Correct Flux auto-generated kustomization details Update README to reflect current repository state Add comprehensive architectural documentation Add comprehensive architectural documentation for generators Add comprehensive UX design document and recommendations Update project status and document remaining features Add comprehensive plugin architecture design Update CLAUDE.md with current project priorities and status Update CLAUDE.md with current project status and accurate metrics Update user documentation with current project state Add detailed explanation of CEL Validation Enhancement task Add comprehensive repository review and task management system Update task statuses after upstream rebase Add comprehensive puzl-cloud/kubesdk review with kure comparison Add task #1 for CEL validation enhancement Add workflow guidelines to tasks.md Remove references to non-existent demo-internals make target Add HPA and PDB builder tasks for Crane OAM support Add Crane integration documentation Add tasks README and update task 03 status Add quickstart guide Expand README with end-to-end examples Mark high-priority tasks 1-5, 23, 24 as completed Mark task #8 as completed Add comprehensive GoDoc documentation Mark task #10 as completed Mark task #6 as completed Mark tasks #7, #9, #11, #12 as completed Fixed Separate helper group comments Add missing unstructured import to patch CLI Correct type usage in generators package tests Resolve all layout module test failures Ensure all manifest directories have kustomization.yaml for GitOps compliance Resolve test failures in launcher module Resolve CLI test output capture issues Resolve all failing tests and improve TOML patch support Correct appworkload test to match ServiceConfig structure Update demo and kure commands to use new GVK-based ApplicationWrapper Resolve intermittent test failures in cmd/demo package Resolve stdout capture synchronization in demo tests Configure golangci-lint compatibility and resolve linting issues Correct YAML structure in CI workflow Add goimports to make fmt for CI/local parity Add GOPATH/bin to PATH in lint and fmt targets Upgrade Go to 1.24.11 to resolve security vulnerabilities Make max_depth_exceeded test deterministic Fix CVE in mapstructure and add workflow permissions Resolve repo issues across docs, CI, validation, and caching Propagate –strict flag to validator in kurel validate Update K8s compatibility matrix to test supported versions Remove K8s 0.33 from CI compatibility matrix Align mise.toml Go version with CI workflows Lower coverage threshold to 70% to match current main coverage Improve dependabot wildcard pattern matching in validation Block FluxCD major version updates in dependabot Testing Check errors Add runCluster coverage Add comprehensive test coverage for all packages Add comprehensive test coverage for FluxHelm internal package Skip demo integration tests in short mode Skip demo tests when examples directory is missing Fix data race in TestMainFunction Skip max_depth_exceeded test due to resolver bugs Add integration tests for stack generation workflows Add fuzz tests for patch parser Add Kubernetes version matrix to CI Add tests to improve coverage and fix Go version Add Phase 1 coverage for simple getters/setters Add Phase 2 parsing tests, reach 70.5% coverage Add Phase 3 validation tests, reach 100% validation coverage Add Phase 4 stack domain model tests Add Phase 5 layout integrator tests Add wrapper function tests, reach 94.8% gvk coverage Add setter function tests for internal packages Add comprehensive IO table and printer tests Add comprehensive appworkload internal tests Release V0.1.0-alpha.0",
    "tags": [],
    "title": "Releases",
    "uri": "/changelog/releases/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Stack - Core Domain Model The stack package defines the hierarchical domain model at the heart of Kure. It provides the Cluster, Node, Bundle, and Application abstractions used to describe a complete Kubernetes deployment topology.\nOverview Kure models Kubernetes infrastructure as a four-level hierarchy:\nCluster └── Node (tree structure) └── Bundle (deployment unit) └── Application (workload) Each level maps to a concept in GitOps deployment:\nLevel Purpose GitOps Mapping Cluster Target cluster Root directory Node Organizational grouping (e.g., infrastructure, apps) Subdirectory tree Bundle Deployment unit with dependencies Flux Kustomization / ArgoCD Application Application Individual workload or resource set Kubernetes manifests Key Types Cluster The root of the hierarchy, representing a complete cluster configuration.\ncluster := stack.NewCluster(\"production\", rootNode) cluster.SetGitOps(\u0026stack.GitOpsConfig{ Type: \"flux\", }) Node A tree structure for organizing bundles into logical groups. Nodes can have children (sub-nodes) and a package reference for multi-source deployments.\nnode := \u0026stack.Node{ Name: \"infrastructure\", Children: []*stack.Node{childNode}, Bundle: []*stack.Bundle{monitoringBundle}, } Bundle A deployment unit corresponding to a single GitOps resource (e.g., a Flux Kustomization). Bundles support dependency ordering via DependsOn.\nbundle, err := stack.NewBundle(\"monitoring\", apps, labels) bundle.DependsOn = []string{\"cert-manager\"} bundle.Interval = \"10m\" Application An individual Kubernetes workload. Applications use the ApplicationConfig interface to generate their resources.\napp := stack.NewApplication(\"prometheus\", \"monitoring\", prometheusConfig) resources, err := app.Generate() ApplicationConfig Interface Implement this interface to define how an application generates its Kubernetes resources:\ntype ApplicationConfig interface { Generate(*Application) ([]*client.Object, error) } Optional Validation ApplicationConfig implementations can optionally implement the Validator interface to validate configuration before resource generation:\ntype Validator interface { Validate() error } When present, Application.Generate() calls Validate() automatically before Generate(). If validation fails, generation stops and the error is returned with application context:\ntype myConfig struct { Port int } func (c *myConfig) Validate() error { if c.Port \u003c= 0 { return errors.New(\"port must be positive\") } return nil } func (c *myConfig) Generate(app *stack.Application) ([]*client.Object, error) { // Only called if Validate() passes (or is not implemented) ... } Validation errors are wrapped with application name and namespace:\nvalidation failed for application \"web\" in namespace \"prod\": port must be positive Configs that do not implement Validator continue to work without changes.\nFluent Builder API For ergonomic cluster construction, use the fluent builder:\ncluster := stack.NewClusterBuilder(\"production\"). WithNode(\"infrastructure\"). WithBundle(\"monitoring\"). WithApplication(\"prometheus\", appConfig). End(). End(). Build() Workflow System The package provides a pluggable workflow abstraction for GitOps tool integration:\n// Create a workflow for your GitOps tool wf, err := stack.NewWorkflow(\"flux\") // Generate GitOps resources from the cluster definition objects, err := wf.GenerateFromCluster(cluster) Supported workflow providers: \"flux\" / \"fluxcd\" and \"argo\" / \"argocd\".\nSource References Bundles and nodes can reference different source types for multi-source deployments:\nnode.SetPackageRef(\u0026stack.SourceRef{ Kind: \"OCIRepository\", Name: \"my-registry\", Namespace: \"flux-system\", URL: \"oci://registry.example.com/manifests\", Tag: \"v1.0.0\", }) Related Packages stack/fluxcd - FluxCD workflow engine implementation stack/generators - Application generator system stack/layout - Manifest directory organization stack/argocd - ArgoCD workflow (deferred)",
    "description": "Stack - Core Domain Model The stack package defines the hierarchical domain model at the heart of Kure. It provides the Cluster, Node, Bundle, and Application abstractions used to describe a complete Kubernetes deployment topology.\nOverview Kure models Kubernetes infrastructure as a four-level hierarchy:\nCluster └── Node (tree structure) └── Bundle (deployment unit) └── Application (workload) Each level maps to a concept in GitOps deployment:\nLevel Purpose GitOps Mapping Cluster Target cluster Root directory Node Organizational grouping (e.g., infrastructure, apps) Subdirectory tree Bundle Deployment unit with dependencies Flux Kustomization / ArgoCD Application Application Individual workload or resource set Kubernetes manifests Key Types Cluster The root of the hierarchy, representing a complete cluster configuration.",
    "tags": [],
    "title": "Stack",
    "uri": "/api-reference/stack/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Guides",
    "content": "Using Kure as a Library Kure is primarily a Go library. This guide covers the basics of importing it, creating resources, and generating YAML output.\nInstallation go get github.com/go-kure/kure Creating Resources Kure provides typed builder functions for Kubernetes and FluxCD resources.\nFluxCD Resources import \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" // Create a GitRepository source repo := fluxcd.GitRepository(\u0026fluxcd.GitRepositoryConfig{ Name: \"my-repo\", Namespace: \"flux-system\", URL: \"https://github.com/org/repo\", Branch: \"main\", Interval: \"5m\", }) // Create a Kustomization that references the source ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production\", Interval: \"10m\", Prune: true, SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"my-repo\", }, }) See the FluxCD Builders reference for all available resource types.\nGenerating YAML Use the io package to serialize resources:\nimport \"github.com/go-kure/kure/pkg/io\" // Serialize a single object data, err := io.Marshal(deployment) // Write multiple objects to stdout as YAML err := io.PrintObjectsAsYAML(objects, os.Stdout) // Save to file err := io.SaveFile(\"output.yaml\", deployment) Clean YAML encoding When encoding resources exported from a cluster, server-managed metadata fields (managedFields, resourceVersion, uid, etc.) clutter the output. The default encoding strips all of these automatically:\n// Default: strips all server-set fields and uses standard key order data, err := io.EncodeObjectsToYAMLWithOptions(objects, io.EncodeOptions{ KubernetesFieldOrder: true, }) Use ServerFieldStripping to control the level of stripping:\n// Preserve server fields (e.g. for debugging) data, err := io.EncodeObjectsToYAMLWithOptions(objects, io.EncodeOptions{ ServerFieldStripping: io.StripServerFieldsNone, }) See the IO reference for all output formats and stripping options.\nWorking with the Domain Model For more complex scenarios, use the Stack package to define cluster topologies:\nimport \"github.com/go-kure/kure/pkg/stack\" cluster := stack.NewClusterBuilder(\"production\"). WithNode(\"apps\"). WithBundle(\"web\"). WithApplication(\"frontend\", frontendConfig). End(). End(). Build() Then use the Flux Engine and Layout Engine to generate a complete GitOps repository structure. See the Generating Flux Manifests guide for the full workflow.\nError Handling All Kure packages use the errors package:\nimport \"github.com/go-kure/kure/pkg/errors\" if err != nil { return errors.Wrap(err, \"failed to generate manifests\") } Next Steps Generating Flux Manifests for the complete workflow API Reference for all package documentation Examples for working code samples",
    "description": "Using Kure as a Library Kure is primarily a Go library. This guide covers the basics of importing it, creating resources, and generating YAML output.\nInstallation go get github.com/go-kure/kure Creating Resources Kure provides typed builder functions for Kubernetes and FluxCD resources.\nFluxCD Resources import \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" // Create a GitRepository source repo := fluxcd.GitRepository(\u0026fluxcd.GitRepositoryConfig{ Name: \"my-repo\", Namespace: \"flux-system\", URL: \"https://github.com/org/repo\", Branch: \"main\", Interval: \"5m\", }) // Create a Kustomization that references the source ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production\", Interval: \"10m\", Prune: true, SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"my-repo\", }, }) See the FluxCD Builders reference for all available resource types.",
    "tags": [],
    "title": "Using Kure as a Library",
    "uri": "/guides/library-usage/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Concepts Understand the ideas behind Kure’s design.\nArchitecture - System architecture and component overview Domain Model - The Cluster, Node, Bundle, Application hierarchy Design Philosophy - Type-safe builders, no templating, GitOps-native",
    "description": "Concepts Understand the ideas behind Kure’s design.\nArchitecture - System architecture and component overview Domain Model - The Cluster, Node, Bundle, Application hierarchy Design Philosophy - Type-safe builders, no templating, GitOps-native",
    "tags": [],
    "title": "Concepts",
    "uri": "/concepts/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Concepts",
    "content": "Domain Model Kure models Kubernetes infrastructure as a four-level hierarchy. Each level maps to a concept in GitOps deployment workflows.\nThe Hierarchy Cluster └── Node (tree structure) └── Bundle (deployment unit) └── Application (workload) Cluster The root of the hierarchy, representing a target Kubernetes cluster. A cluster has a name, a tree of nodes, and GitOps configuration specifying which workflow engine to use (Flux or ArgoCD).\nNode An organizational grouping within a cluster. Nodes form a tree structure — for example, a cluster might have top-level nodes for infrastructure and applications, each with child nodes for specific concerns.\nNodes map to directory structures in the GitOps repository. Each node can also reference a source (Git repository, OCI registry, S3 bucket) for multi-source deployments.\nBundle A deployment unit corresponding to a single GitOps reconciliation resource (e.g., a Flux Kustomization or ArgoCD Application). Bundles contain applications and support:\nDependency ordering via DependsOn (e.g., “deploy cert-manager before my app”) Reconciliation settings: interval, pruning, timeouts Labels and annotations for metadata Application An individual Kubernetes workload or resource set. Applications implement the ApplicationConfig interface, which defines how to generate Kubernetes resource objects.\nFluent Builder API For ergonomic cluster construction:\ncluster := stack.NewClusterBuilder(\"production\"). WithNode(\"infrastructure\"). WithBundle(\"cert-manager\"). WithApplication(\"cert-manager\", certManagerConfig). End(). WithBundle(\"monitoring\"). WithApplication(\"prometheus\", prometheusConfig). End(). End(). WithNode(\"applications\"). WithBundle(\"web-apps\"). WithApplication(\"frontend\", frontendConfig). WithApplication(\"api\", apiConfig). End(). End(). Build() How It Maps to GitOps The domain model maps directly to a GitOps repository structure:\nclusters/ production/ # Cluster infrastructure/ # Node cert-manager/ # Bundle → Flux Kustomization cert-manager/ # Application → K8s manifests monitoring/ # Bundle → Flux Kustomization prometheus/ # Application → K8s manifests applications/ # Node web-apps/ # Bundle → Flux Kustomization frontend/ # Application → K8s manifests api/ # Application → K8s manifests The Layout Engine handles this mapping, and the Flux Engine generates the corresponding Flux Kustomization resources.\nFurther Reading Stack package reference for API details Flux workflow guide for end-to-end usage Architecture for system-level design",
    "description": "Domain Model Kure models Kubernetes infrastructure as a four-level hierarchy. Each level maps to a concept in GitOps deployment workflows.\nThe Hierarchy Cluster └── Node (tree structure) └── Bundle (deployment unit) └── Application (workload) Cluster The root of the hierarchy, representing a target Kubernetes cluster. A cluster has a name, a tree of nodes, and GitOps configuration specifying which workflow engine to use (Flux or ArgoCD).\nNode An organizational grouping within a cluster. Nodes form a tree structure — for example, a cluster might have top-level nodes for infrastructure and applications, each with child nodes for specific concerns.",
    "tags": [],
    "title": "Domain Model",
    "uri": "/concepts/domain-model/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Flux Engine - FluxCD Workflow Implementation The fluxcd package implements the stack.Workflow interface for FluxCD, providing complete Flux resource generation from domain model definitions.\nOverview The Flux engine transforms Kure’s hierarchical domain model (Cluster, Node, Bundle, Application) into FluxCD resources (Kustomizations, source references) organized in a GitOps-ready directory structure.\nThe engine is composed of three specialized components:\nComponent Responsibility ResourceGenerator Generates Flux resources from domain objects LayoutIntegrator Integrates resources into directory structures BootstrapGenerator Creates Flux bootstrap manifests Quick Start import \"github.com/go-kure/kure/pkg/stack/fluxcd\" // Create engine with defaults engine := fluxcd.Engine() // Generate all Flux resources for a cluster objects, err := engine.GenerateFromCluster(cluster) // Or with custom configuration engine = fluxcd.EngineWithConfig( layout.KustomizationExplicit, layout.FluxSeparate, ) Engine Construction // Default engine engine := fluxcd.Engine() // Engine with specific kustomization mode engine := fluxcd.EngineWithMode(layout.KustomizationExplicit) // Engine with full configuration engine := fluxcd.EngineWithConfig(mode, placement) // Engine with custom components engine := fluxcd.NewWorkflowEngine() Resource Generation Generate Flux resources at different hierarchy levels:\n// From entire cluster objects, err := engine.GenerateFromCluster(cluster) // From a single node objects, err := engine.GenerateFromNode(node) // From a single bundle objects, err := engine.GenerateFromBundle(bundle) Each bundle produces a Flux Kustomization resource with:\nPath matching the layout directory structure Source reference from the node’s package ref Dependency ordering from Bundle.DependsOn Interval and pruning configuration Layout Integration Combine resource generation with directory structure:\n// Create layout with Flux resources integrated ml, err := engine.CreateLayoutWithResources(cluster, rules) // Write to disk err = layout.WriteManifest(ml, \"./clusters\") Bootstrap Generation Generate Flux system bootstrap manifests:\nbootstrapConfig := \u0026stack.BootstrapConfig{ Enabled: true, FluxMode: \"install\", FluxVersion: \"v2.6.4\", SourceRef: sourceRef, } objects, err := engine.GenerateBootstrap(bootstrapConfig, rootNode) Configuration Kustomization Mode Controls how kustomization.yaml files reference resources:\nKustomizationExplicit - Lists all manifest files explicitly KustomizationRecursive - References subdirectories only Flux Placement Controls where Flux Kustomization resources are placed:\nFluxSeparate - Flux resources in a separate directory tree FluxIntegrated - Flux resources alongside application manifests Related Packages stack - Core domain model stack/layout - Manifest directory organization kubernetes/fluxcd - Low-level Flux resource builders",
    "description": "Flux Engine - FluxCD Workflow Implementation The fluxcd package implements the stack.Workflow interface for FluxCD, providing complete Flux resource generation from domain model definitions.\nOverview The Flux engine transforms Kure’s hierarchical domain model (Cluster, Node, Bundle, Application) into FluxCD resources (Kustomizations, source references) organized in a GitOps-ready directory structure.\nThe engine is composed of three specialized components:\nComponent Responsibility ResourceGenerator Generates Flux resources from domain objects LayoutIntegrator Integrates resources into directory structures BootstrapGenerator Creates Flux bootstrap manifests Quick Start import \"github.com/go-kure/kure/pkg/stack/fluxcd\" // Create engine with defaults engine := fluxcd.Engine() // Generate all Flux resources for a cluster objects, err := engine.GenerateFromCluster(cluster) // Or with custom configuration engine = fluxcd.EngineWithConfig( layout.KustomizationExplicit, layout.FluxSeparate, ) Engine Construction // Default engine engine := fluxcd.Engine() // Engine with specific kustomization mode engine := fluxcd.EngineWithMode(layout.KustomizationExplicit) // Engine with full configuration engine := fluxcd.EngineWithConfig(mode, placement) // Engine with custom components engine := fluxcd.NewWorkflowEngine() Resource Generation Generate Flux resources at different hierarchy levels:",
    "tags": [],
    "title": "Flux Engine",
    "uri": "/api-reference/flux-engine/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Guides",
    "content": "Generating Flux Manifests This guide walks through the complete workflow for generating a GitOps repository structure with Flux resources using Kure.\nOverview The workflow has four stages:\nDefine the cluster topology using the domain model Select the Flux workflow engine Generate Flux resources and directory layout Write manifests to disk Step 1: Define the Cluster Use the fluent builder to define your cluster’s structure:\nimport \"github.com/go-kure/kure/pkg/stack\" cluster := stack.NewClusterBuilder(\"production\"). WithNode(\"infrastructure\"). WithBundle(\"cert-manager\"). WithApplication(\"cert-manager\", certManagerConfig). End(). End(). WithNode(\"applications\"). WithBundle(\"web-tier\"). WithApplication(\"frontend\", frontendConfig). WithApplication(\"api-gateway\", apiConfig). End(). End(). Build() Each bundle becomes a Flux Kustomization, and each application generates its Kubernetes manifests.\nStep 2: Create the Flux Engine import ( \"github.com/go-kure/kure/pkg/stack/fluxcd\" \"github.com/go-kure/kure/pkg/stack/layout\" ) engine := fluxcd.EngineWithConfig( layout.KustomizationExplicit, // List files in kustomization.yaml layout.FluxSeparate, // Flux resources in separate tree ) See the Flux Engine reference for configuration options.\nStep 3: Generate Resources with Layout // Define layout rules rules := layout.LayoutRules{ NodeGrouping: layout.GroupByName, BundleGrouping: layout.GroupByName, ApplicationGrouping: layout.GroupByName, FilePer: layout.FilePerResource, } // Generate layout with Flux resources integrated ml, err := engine.CreateLayoutWithResources(cluster, rules) if err != nil { return errors.Wrap(err, \"failed to create layout\") } Step 4: Write to Disk err := layout.WriteManifest(ml, \"./clusters\") This produces a directory structure like:\nclusters/ production/ infrastructure/ cert-manager/ cert-manager/ deployment.yaml service.yaml kustomization.yaml kustomization.yaml # Flux Kustomization applications/ web-tier/ frontend/ deployment.yaml service.yaml api-gateway/ deployment.yaml service.yaml kustomization.yaml # Flux Kustomization Layout Configuration The Layout Engine supports multiple grouping and file organization strategies:\nOption Values Effect NodeGrouping GroupByName, GroupFlat Create subdirectories per node or flatten BundleGrouping GroupByName, GroupFlat Create subdirectories per bundle or flatten ApplicationGrouping GroupByName, GroupFlat Create subdirectories per app or flatten FilePer FilePerResource, FilePerKind One file per resource or group by kind FluxPlacement FluxSeparate, FluxIntegrated Separate or inline Flux resources Bootstrap Generate Flux system bootstrap manifests:\nbootstrapConfig := \u0026stack.BootstrapConfig{ Enabled: true, FluxMode: \"install\", FluxVersion: \"v2.6.4\", SourceRef: sourceRef, } objects, err := engine.GenerateBootstrap(bootstrapConfig, rootNode) Further Reading Stack - Domain model reference Flux Engine - Workflow engine reference Layout Engine - Directory organization reference Generators - Application generator guide",
    "description": "Generating Flux Manifests This guide walks through the complete workflow for generating a GitOps repository structure with Flux resources using Kure.\nOverview The workflow has four stages:\nDefine the cluster topology using the domain model Select the Flux workflow engine Generate Flux resources and directory layout Write manifests to disk Step 1: Define the Cluster Use the fluent builder to define your cluster’s structure:\nimport \"github.com/go-kure/kure/pkg/stack\" cluster := stack.NewClusterBuilder(\"production\"). WithNode(\"infrastructure\"). WithBundle(\"cert-manager\"). WithApplication(\"cert-manager\", certManagerConfig). End(). End(). WithNode(\"applications\"). WithBundle(\"web-tier\"). WithApplication(\"frontend\", frontendConfig). WithApplication(\"api-gateway\", apiConfig). End(). End(). Build() Each bundle becomes a Flux Kustomization, and each application generates its Kubernetes manifests.",
    "tags": [],
    "title": "Generating Flux Manifests",
    "uri": "/guides/flux-workflow/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Examples",
    "content": "Generator Examples This directory contains examples of the GVK-based generator system for Kure.\nOverview Kure uses a Group, Version, Kind (GVK) pattern similar to Kubernetes for identifying generator types. Each generator:\nHas a unique GVK identifier Implements the ApplicationConfig interface Can generate specific types of Kubernetes resources Available Generators AppWorkload (generators.gokure.dev/v1alpha1) Creates standard Kubernetes workloads (Deployments, StatefulSets, DaemonSets) with associated resources.\nExample: appworkload.yaml This example creates:\nA Deployment with 3 replicas A LoadBalancer Service An Ingress resource Proper resource limits and volume mounts FluxHelm (generators.gokure.dev/v1alpha1) Creates Flux HelmRelease resources with their source configurations.\nExamples:\nfluxhelm.yaml - Traditional Helm repository source fluxhelm-oci.yaml - OCI registry source These examples demonstrate:\nHelmRepository and OCIRepository sources Values customization Release configuration options Flux-specific settings (interval, timeout, suspend) KurelPackage (generators.gokure.dev/v1alpha1) Generates Kubernetes resource objects from kurel packages. Generate() collects resources from the package structure and returns them as typed objects, making kurel packages usable in the stack generation pipeline.\nUsage To parse and generate resources from these examples:\npackage main import ( \"fmt\" \"io/ioutil\" \"gopkg.in/yaml.v3\" \"github.com/go-kure/kure/pkg/stack\" _ \"github.com/go-kure/kure/pkg/stack/generators/appworkload\" _ \"github.com/go-kure/kure/pkg/stack/generators/fluxhelm\" _ \"github.com/go-kure/kure/pkg/stack/generators/kurelpackage\" ) func main() { // Read YAML file data, err := ioutil.ReadFile(\"appworkload.yaml\") if err != nil { panic(err) } // Parse into ApplicationWrapper var wrapper stack.ApplicationWrapper if err := yaml.Unmarshal(data, \u0026wrapper); err != nil { panic(err) } // Convert to Application app := wrapper.ToApplication() // Generate Kubernetes resources resources, err := app.Config.Generate(app) if err != nil { panic(err) } fmt.Printf(\"Generated %d resources\\n\", len(resources)) } Creating New Generators To create a new generator type:\nCreate a package under pkg/stack/generators/\u003ctype\u003e/ Implement the ApplicationConfig interface Register with GVK in init() Add version files (v1alpha1.go, etc.) Example structure:\ngenerators/ └── mytype/ ├── v1alpha1.go # Version implementation ├── internal/ # Internal logic │ └── mytype.go └── doc.go # Documentation GVK Convention All generators follow the pattern:\nGroup: generators.gokure.dev Version: v1alpha1, v1beta1, v1 Kind: Generator type name (e.g., AppWorkload, FluxHelm) This allows for:\nClear type identification Version evolution Backward compatibility Schema validation",
    "description": "Generator Examples This directory contains examples of the GVK-based generator system for Kure.\nOverview Kure uses a Group, Version, Kind (GVK) pattern similar to Kubernetes for identifying generator types. Each generator:\nHas a unique GVK identifier Implements the ApplicationConfig interface Can generate specific types of Kubernetes resources Available Generators AppWorkload (generators.gokure.dev/v1alpha1) Creates standard Kubernetes workloads (Deployments, StatefulSets, DaemonSets) with associated resources.\nExample: appworkload.yaml This example creates:\nA Deployment with 3 replicas A LoadBalancer Service An Ingress resource Proper resource limits and volume mounts FluxHelm (generators.gokure.dev/v1alpha1) Creates Flux HelmRelease resources with their source configurations.",
    "tags": [],
    "title": "Generators",
    "uri": "/examples/generators/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Contributing",
    "content": "GitHub Workflows Documentation This document provides an overview of all GitHub Actions workflows used in the kure project.\nLast Updated: 2026-02-12\nWorkflow Summary Workflow File Triggers Purpose CI ci.yml push, PR, schedule, manual Comprehensive testing, linting, building, security Auto-Rebase auto-rebase.yml push to main Rebase all open PRs when main is updated Release release.yml version tags GoReleaser-based release with CI validation CI Workflow File: .github/workflows/ci.yml Name: CI\nTriggers Push to: main, develop, release/* Pull requests to: main, develop Schedule: 4am UTC daily (catch external changes) Manual dispatch Concurrency Uses github.sha to avoid duplicate runs:\nSame commit won’t run CI twice (e.g., PR merge → push to main) Different commits run independently concurrency: group: ci-${{ github.sha }} cancel-in-progress: false Job Dependency Graph ┌─────────────────┐ │ lint │ ← Fast checks: go-version, fmt, tidy, vet, lint └────────┬────────┘ │ ┌────┴────┐ ▼ ▼ ┌───────┐ ┌───────────┐ │ test │ │ security │ ← Tests + govulncheck (parallel) └───┬───┘ └───────────┘ │ ▼ ┌───────────────────┐ │ coverage-check │ ← 80% threshold enforcement └─────────┬─────────┘ │ ┌─────┴─────┐ ▼ ▼ ┌───────┐ ┌────────────┐ │ build │ │ k8s-compat │ ← Build artifacts + K8s matrix └───┬───┘ └────────────┘ │ ▼ ┌─────────────────────┐ │ cross-platform │ ← Only on main/release branches └─────────┬───────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ mirror-to-gitlab (main push only, after all checks) │ └─────────────────────────────────────────────────────────────┘ PR-only jobs (parallel, no blocking): ┌──────────────┐ ┌─────────────────┐ ┌────────────┐ │ rebase-check │ │ analyze-changes │ │ docs-check │ └──────────────┘ └─────────────────┘ └────────────┘ Jobs Detail Job Check Name Timeout Dependencies Purpose validate lint 5 min - Go version check, fmt, tidy, vet, lint test test 15 min validate Unit tests, race tests, coverage security Security 10 min validate govulncheck, outdated deps, sensitive file check coverage-check Coverage Check 5 min test 80% threshold, Codecov upload, PR comment build build 10 min coverage-check Build kure, kurel, demo k8s-compat K8s Compatibility 15 min coverage-check K8s 0.34, 0.35 compatibility matrix cross-platform Cross-Platform Build 15 min build linux/darwin/windows × amd64/arm64 (main/release only) rebase-check rebase-check 2 min - Verify PR branch is rebased on main (PR only) analyze-changes Analyze Changes 5 min - Changed files analysis, breaking change warnings (PR only) docs-check Docs Check 5 min - API changes need docs check (PR only) mirror-to-gitlab Mirror to GitLab 5 min build, security, k8s-compat, cross-platform, docs-build Push main and tags to GitLab mirror; fails on divergence (main only) Configuration Go Version: 1.24.13 Golangci-lint Version: v1.64.8 Coverage Threshold: 80% K8s Versions: 0.34, 0.35 Platforms: linux/amd64, linux/arm64, darwin/amd64, darwin/arm64, windows/amd64 Features gotestfmt - Nice formatted test output Fail fast - Jobs depend on validate, so lint failure stops everything Artifact sharing - Coverage uploaded as artifact, reused by coverage-check PR comments - Coverage report comment on PRs Skip draft PRs - if: github.event.pull_request.draft == false Sensitive file check - Warn about potential secrets in code Matrix fail-fast: false - K8s and cross-platform continue if one fails Release Workflow File: .github/workflows/release.yml Name: Release\nTriggers Push tags: v* (e.g., v1.0.0, v0.1.0-alpha.0) Jobs check-ci - Verify CI passed for this commit (waits up to 5 min) validate - Strict tag format, changelog, and version progression validation goreleaser - Cross-platform builds using GoReleaser v2 post-release - Go proxy refresh Configuration Go Version: 1.24.13 Build Tool: GoReleaser v2 Platforms: linux/amd64, linux/arm64, darwin/amd64, darwin/arm64, windows/amd64, windows/arm64 Tag Format: ^v[0-9]+\\.[0-9]+\\.[0-9]+(-alpha\\.[0-9]+|-beta\\.[0-9]+|-rc\\.[0-9]+)?$ Changelog: Required (must have ## v0.1.0 section) CI Status Check Release workflow verifies CI passed before releasing:\ncheck-ci: name: Verify CI passed steps: - name: Check CI status for this commit run: | # Wait up to 5 minutes for CI to complete for i in {1..30}; do STATUS=$(gh api repos/.../commits/$COMMIT_SHA/status --jq '.state') if [ \"$STATUS\" = \"success\" ]; then exit 0; fi if [ \"$STATUS\" = \"failure\" ]; then exit 1; fi sleep 10 done Release Management # Preview release plan locally (dry-run) make release TYPE=alpha # Create release via CI: # Actions \u003e \"Create Release\" \u003e type=alpha \u003e Run workflow Auto-Rebase Workflow File: .github/workflows/auto-rebase.yml Name: Auto-Rebase\nTriggers Push to main (runs after every merge to main) Purpose Automatically rebases all open PRs targeting main when main is updated. This mirrors the GitLab auto-rebase CI template used in other Wharf repositories.\nHow It Works Uses peter-evans/rebase@v4 to:\nFind all open PRs targeting main Rebase each PR branch onto the latest main Force-push the rebased branch (triggers CI re-run) Skip PRs with conflicts (reports them without failing) Configuration Excluded labels: dependencies (Dependabot manages its own branches) Excluded drafts: yes (no point rebasing work-in-progress) Fork protection: only runs on go-kure/kure (forks lack the required secret) Concurrency: cancel-in-progress: true (newer main state supersedes) Authentication Requires AUTO_REBASE_PAT repository secret — a fine-grained PAT with:\nRepository: go-kure/kure only Permissions: Contents: Read+Write, Pull requests: Read A PAT is required because pushes made with GITHUB_TOKEN do not trigger subsequent workflow runs. The PAT ensures CI re-runs on rebased branches.\nTest Jobs in CI Job Matrix Command Uses Makefile? test - go test -json -v ./... ✅ (deps) test - make test-race ✅ test - make test-coverage ✅ Test Targets in Makefile Target Command Used in CI? In precommit? test go test -timeout 30s ./... ✅ ✅ test-race go test -race -timeout 30s ./... ✅ - test-coverage go test -coverprofile=... ./... ✅ - test-integration go test -tags=integration -timeout 5m ./... - - vuln govulncheck ./... ✅ - CI vs Pre-commit Target Tasks Use Case precommit fmt, tidy, lint, test Fast local checks (~10s) ci deps, fmt, tidy, lint, vet, test, test-race, test-coverage, test-integration, build, vuln Comprehensive CI pipeline (~2min) Configuration Standards Go Version All workflows use Go 1.24.13 consistently, defined via environment variable:\nenv: GO_VERSION: '1.24.13' Caching Most workflows use Go module caching:\n- name: Cache Go modules uses: actions/cache@v4 with: path: | ~/.cache/go-build ~/go/pkg/mod key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }} restore-keys: | ${{ runner.os }}-go- Branch Patterns Release branches: release/* (note: not releases/*) Development branches: main, develop Estimated CI Time Scenario Before (4 workflows) After (2 workflows) PR opened ~8 min (duplicate work) ~4 min Push to main ~5 min ~4 min PR merge ~5 min (full re-run) ~0 min (same SHA, skipped) Maintenance Notes When adding/modifying workflows: Update this document with changes Version updates: Run make sync-go-version to update Go version in all files Version check: Run make check-go-version to verify consistency Action versions: Keep GitHub Actions up to date (currently using v4-v6) See Also Makefile - Local development commands CLAUDE.md - Development guidelines mise.toml - Local tool version management",
    "description": "GitHub Workflows Documentation This document provides an overview of all GitHub Actions workflows used in the kure project.\nLast Updated: 2026-02-12\nWorkflow Summary Workflow File Triggers Purpose CI ci.yml push, PR, schedule, manual Comprehensive testing, linting, building, security Auto-Rebase auto-rebase.yml push to main Rebase all open PRs when main is updated Release release.yml version tags GoReleaser-based release with CI validation CI Workflow File: .github/workflows/ci.yml Name: CI\nTriggers Push to: main, develop, release/* Pull requests to: main, develop Schedule: 4am UTC daily (catch external changes) Manual dispatch Concurrency Uses github.sha to avoid duplicate runs:",
    "tags": [],
    "title": "GitHub Workflows",
    "uri": "/contributing/github-workflows/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Concepts",
    "content": "Design Philosophy Kure is built on a few core principles that guide its design and API choices.\nType-Safe Builders Over Templating Traditional Kubernetes tooling relies on string-based templating (Helm, Kustomize overlays, Jsonnet). This creates a class of errors that only surface at deploy time — typos in YAML paths, type mismatches, missing fields.\nKure uses Go’s type system instead:\n// Compile-time checked — typos and type errors are caught by the compiler ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production/apps\", Interval: \"10m\", Prune: true, }) If you misspell a field name, the Go compiler tells you immediately.\nGitOps-Native Output Kure generates plain Kubernetes YAML manifests organized for GitOps tools. The output is not a runtime artifact — it’s files in a directory structure that Flux (or eventually ArgoCD) reconciles.\nThis means:\nPredictable output — same inputs always produce the same manifests Tool independence — the output is standard Kubernetes YAML Debugging simplicity — you can read the generated manifests directly Git-friendly — changes are visible as diffs Interface-Driven Design Kure separates concerns through interfaces:\nApplicationConfig — how an application generates its resources Workflow — how a GitOps tool creates reconciliation resources Generator registry — pluggable application types via GVK This allows new application types and GitOps tools to be added without modifying the core domain model.\n“Kurel Just Generates YAML” The kurel package system follows a simple principle: it takes base manifests, applies patches, resolves variables, and writes YAML files. It’s not a runtime system, not a controller, not an orchestrator.\nThis constraint keeps the system simple and auditable. You can always inspect exactly what will be deployed by looking at the generated output.\nComposition Over Configuration Rather than a single monolithic configuration format, Kure composes small, focused packages:\nPackage Responsibility stack Domain model (what to deploy) stack/fluxcd Flux resource generation (how to deploy) stack/layout Directory organization (where to write) patch Resource modification (how to customize) io Serialization (how to read/write) Each package can be used independently or composed together for complete workflows.",
    "description": "Design Philosophy Kure is built on a few core principles that guide its design and API choices.\nType-Safe Builders Over Templating Traditional Kubernetes tooling relies on string-based templating (Helm, Kustomize overlays, Jsonnet). This creates a class of errors that only surface at deploy time — typos in YAML paths, type mismatches, missing fields.\nKure uses Go’s type system instead:\n// Compile-time checked — typos and type errors are caught by the compiler ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production/apps\", Interval: \"10m\", Prune: true, }) If you misspell a field name, the Go compiler tells you immediately.",
    "tags": [],
    "title": "Design Philosophy",
    "uri": "/concepts/design-philosophy/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Generators - Application Generator System The generators package provides a type-safe system for creating Kubernetes application workloads from configuration. Generators implement the stack.ApplicationConfig interface, allowing them to be used as applications within the domain model.\nOverview Generators use the GroupVersionKind (GVK) type system to identify and instantiate application configurations. Each generator is registered in the stack package’s global registry and can be referenced by its GVK identifier.\nAvailable Generators Generator GVK Description AppWorkload generators/AppWorkload General-purpose application workload with Deployment, Service, ConfigMap FluxHelm generators/FluxHelm HelmRelease-based application using Flux KurelPackage generators/KurelPackage Kurel package reference for pre-built application packages Usage Creating a Generator from GVK import \"github.com/go-kure/kure/pkg/stack\" // Create application config by apiVersion and kind config, err := stack.CreateApplicationConfig(\"generators.gokure.dev/v1alpha1\", \"AppWorkload\") // Use in domain model app := stack.NewApplication(\"my-app\", \"default\", config) YAML Configuration Format Generators are typically configured via YAML:\napiVersion: generators/v1 kind: AppWorkload metadata: name: my-web-app spec: image: nginx:1.25 replicas: 3 ports: - containerPort: 80 servicePort: 80 env: - name: LOG_LEVEL value: info Registry Register custom generators:\nstack.RegisterApplicationConfig(gvk.GVK{ Group: \"mycompany.dev\", Version: \"v1\", Kind: \"CustomApp\", }, func() stack.ApplicationConfig { return \u0026MyCustomConfig{} }) Query available generators:\n// List all registered generator GVKs gvks := stack.ListApplicationConfigGVKs() Sub-packages appworkload General-purpose application generator that produces:\nDeployment with configurable replicas, image, resources Service with port mappings Optional ConfigMap for configuration data Optional ServiceAccount fluxhelm Generates Flux HelmRelease resources for Helm-based applications:\nHelmRelease with chart reference HelmRepository source (if needed) Values configuration kurelpackage Generates Kubernetes resource objects from kurel packages. The Generate() method delegates to GeneratePackageFiles(), extracts files under the resources/ prefix, and parses each one into typed client.Object values. Non-resource files (kurel.yaml, patches, values, extensions) are excluded — they are package metadata. This makes KurelPackage configs usable in the stack generation pipeline alongside other generators.\nRelated Packages stack - Core domain model and ApplicationConfig interface stack/fluxcd - Flux workflow engine",
    "description": "Generators - Application Generator System The generators package provides a type-safe system for creating Kubernetes application workloads from configuration. Generators implement the stack.ApplicationConfig interface, allowing them to be used as applications within the domain model.\nOverview Generators use the GroupVersionKind (GVK) type system to identify and instantiate application configurations. Each generator is registered in the stack package’s global registry and can be referenced by its GVK identifier.\nAvailable Generators Generator GVK Description AppWorkload generators/AppWorkload General-purpose application workload with Deployment, Service, ConfigMap FluxHelm generators/FluxHelm HelmRelease-based application using Flux KurelPackage generators/KurelPackage Kurel package reference for pre-built application packages Usage Creating a Generator from GVK import \"github.com/go-kure/kure/pkg/stack\" // Create application config by apiVersion and kind config, err := stack.CreateApplicationConfig(\"generators.gokure.dev/v1alpha1\", \"AppWorkload\") // Use in domain model app := stack.NewApplication(\"my-app\", \"default\", config) YAML Configuration Format Generators are typically configured via YAML:",
    "tags": [],
    "title": "Generators",
    "uri": "/api-reference/generators/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Guides Step-by-step guides for common Kure workflows.\nUsing Kure as a Library - Import paths, creating resources, generating YAML Generating Flux Manifests - End-to-end cluster definition to disk Working with Generators - The GVK system and application generators Patching Resources - JSONPath patching and TOML patch format Building Kurel Packages - Creating reusable application packages",
    "description": "Guides Step-by-step guides for common Kure workflows.\nUsing Kure as a Library - Import paths, creating resources, generating YAML Generating Flux Manifests - End-to-end cluster definition to disk Working with Generators - The GVK system and application generators Patching Resources - JSONPath patching and TOML patch format Building Kurel Packages - Creating reusable application packages",
    "tags": [],
    "title": "Guides",
    "uri": "/guides/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Examples",
    "content": "Frigate Kurel Package This is a Kurel package for deploying Frigate , a complete and local NVR designed for Home Assistant with AI object detection.\nOverview Frigate is a complete and local NVR designed for Home Assistant with AI object detection. It uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.\nPrerequisites Kubernetes cluster Coral USB TPU device (for hardware acceleration) Node labeled with coral-usb=true where the Coral USB is attached MQTT broker (for Home Assistant integration) Storage provisioner for persistent volumes cert-manager (for TLS certificates) Installation Basic Installation kurel build examples/kurel/frigate | kubectl apply -f - Installation with Custom Values Create a values file my-values.yaml: app: namespace: my-frigate image: tag: 0.13.0 service: loadBalancerIP: 10.0.0.100 ingress: hostname: frigate.mydomain.com storage: size: 200Gi Build and deploy: kurel build examples/kurel/frigate --values my-values.yaml | kubectl apply -f - Using Patches Apply environment-specific patches:\n# For production environment kurel build examples/kurel/frigate --patch production | kubectl apply -f - # For development environment kurel build examples/kurel/frigate --patch development | kubectl apply -f - # For high availability setup kurel build examples/kurel/frigate --patch high-availability | kubectl apply -f - Configuration Key Parameters Parameter Description Default app.namespace Namespace to deploy into frigate app.image.repository Frigate image repository ghcr.io/blakeblackshear/frigate app.image.tag Frigate image tag 0.12.0 service.type Service type LoadBalancer service.loadBalancerIP Static IP for LoadBalancer 172.32.104.0 ingress.enabled Enable ingress true ingress.hostname Hostname for ingress frigate.home.vanginderachter.be storage.size PVC storage size 100Gi storage.storageClass Storage class name local-path mqtt.host MQTT broker host mqtt-broker-home.mqttbroker detector.type Detector type edgetpu detector.device Detector device usb Secrets Management This package requires several secrets to be configured:\nMQTT Password: Create a secret named mqttuser with key FRIGATE_MQTT_PASSWORD Camera Passwords: Create a secret named frigate-camera-secrets with keys for each camera Frigate Plus API Key: Create a secret named frigate-secrets with key plus-api-key Example using kubectl:\nkubectl create secret generic mqttuser \\ --from-literal=FRIGATE_MQTT_PASSWORD=your-mqtt-password \\ -n frigate kubectl create secret generic frigate-camera-secrets \\ --from-literal=cam0-password=password0 \\ --from-literal=cam1-password=password1 \\ --from-literal=cam2-password=password2 \\ --from-literal=cam3-password=password3 \\ --from-literal=cam360-password=password360 \\ -n frigate For production, consider using SealedSecrets or External Secrets Operator.\nCamera Configuration The actual camera configuration should be added to the ConfigMap in resources/configmap.yaml. Here’s an example:\ncameras: front_door: ffmpeg: inputs: - path: rtsp://{FRIGATE_CAM_USERNAME}:{FRIGATE_CAM0_PASSWORD}@192.168.1.100:554/stream1 roles: - detect - record detect: width: 1920 height: 1080 fps: 5 record: enabled: true retain: days: 7 snapshots: enabled: true Hardware Acceleration This package is configured to use a Coral USB TPU for hardware acceleration. The deployment will be scheduled on nodes labeled with coral-usb=true.\nTo label a node:\nkubectl label node \u003cnode-name\u003e coral-usb=true Monitoring The deployment includes liveness and readiness probes to ensure Frigate is running correctly.\nTroubleshooting Pod not scheduling Ensure a node is labeled with coral-usb=true Check if the Coral USB device is properly connected MQTT connection issues Verify MQTT broker is running and accessible Check MQTT credentials in secrets Storage issues Ensure storage class exists and can provision volumes Check available storage capacity License This Kurel package is provided as-is. Frigate itself is licensed under the MIT License.",
    "description": "Frigate Kurel Package This is a Kurel package for deploying Frigate , a complete and local NVR designed for Home Assistant with AI object detection.\nOverview Frigate is a complete and local NVR designed for Home Assistant with AI object detection. It uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.\nPrerequisites Kubernetes cluster Coral USB TPU device (for hardware acceleration) Node labeled with coral-usb=true where the Coral USB is attached MQTT broker (for Home Assistant integration) Storage provisioner for persistent volumes cert-manager (for TLS certificates) Installation Basic Installation kurel build examples/kurel/frigate | kubectl apply -f - Installation with Custom Values Create a values file my-values.yaml: app: namespace: my-frigate image: tag: 0.13.0 service: loadBalancerIP: 10.0.0.100 ingress: hostname: frigate.mydomain.com storage: size: 200Gi Build and deploy: kurel build examples/kurel/frigate --values my-values.yaml | kubectl apply -f - Using Patches Apply environment-specific patches:",
    "tags": [],
    "title": "Kurel Frigate",
    "uri": "/examples/kurel-frigate/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Guides",
    "content": "Working with Generators Generators provide a type-safe way to create application workloads from configuration. They implement the ApplicationConfig interface and are identified by GroupVersionKind (GVK) strings.\nGetting Started The fastest way to start a new project is with kure init:\nkure init my-cluster This creates a ready-to-use directory structure with cluster.yaml and an example application under apps/. You can then generate manifests with:\nkure generate cluster cluster.yaml See kure init --help for options like --gitops argocd.\nThe GVK System Each generator is registered with a GVK identifier that uniquely identifies its type:\nGVK Generator Output generators/AppWorkload AppWorkload Deployment, Service, ConfigMap generators/FluxHelm FluxHelm HelmRelease, HelmRepository generators/KurelPackage KurelPackage Kubernetes resources from kurel packages Using Generators From Code import \"github.com/go-kure/kure/pkg/stack/generators\" // Look up generator by GVK factory, err := generators.GetGenerator(\"generators/AppWorkload\") // Create config from YAML data config, err := factory.FromConfig(yamlData) // Use in the domain model app := stack.NewApplication(\"my-app\", \"default\", config) From YAML Configuration Generators can be configured via YAML files:\napiVersion: generators/v1 kind: AppWorkload metadata: name: web-frontend spec: image: nginx:1.25 replicas: 3 ports: - containerPort: 80 servicePort: 80 env: - name: LOG_LEVEL value: info Listing Available Generators // List all registered generator GVKs gvks := generators.ListRegistered() Built-in Generators AppWorkload Generates a complete application deployment:\nDeployment with configurable replicas, image, resource limits Service with port mappings Optional ConfigMap for configuration data Optional ServiceAccount FluxHelm Generates Flux HelmRelease resources:\nHelmRelease with chart reference and values HelmRepository source (when needed) KurelPackage Generates Kubernetes resource objects from kurel packages. Generate() delegates to GeneratePackageFiles(), extracts the resource files from the package, and parses them into typed objects. Non-resource metadata (kurel.yaml, patches, values, extensions) is excluded from the output. This allows kurel packages to participate in the stack generation pipeline alongside code-generated resources.\nCustom Generators Register your own generators:\ngenerators.Register(\"mycompany/CustomApp\", \u0026MyGeneratorFactory{}) The factory must implement the generator interface, providing a FromConfig method that returns an ApplicationConfig.\nFurther Reading Generators reference for API details Generator examples for working samples Flux workflow for using generators in clusters",
    "description": "Working with Generators Generators provide a type-safe way to create application workloads from configuration. They implement the ApplicationConfig interface and are identified by GroupVersionKind (GVK) strings.\nGetting Started The fastest way to start a new project is with kure init:\nkure init my-cluster This creates a ready-to-use directory structure with cluster.yaml and an example application under apps/. You can then generate manifests with:\nkure generate cluster cluster.yaml See kure init --help for options like --gitops argocd.",
    "tags": [],
    "title": "Working with Generators",
    "uri": "/guides/generators/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Examples Practical examples of using Kure to generate Kubernetes configurations.\nMounted Examples These examples include full documentation:\nPatches - Declarative patching with TOML and YAML formats Generators - Resource generation using the GVK system Kurel Frigate - Building a complete kurel package Validation - Resource validation patterns Additional Examples These examples are available in the examples/ directory on GitHub:\nApp Workloads (examples/appworkloads/) - Application workload generation Bootstrap (examples/bootstrap/) - Flux bootstrap configuration Clusters (examples/clusters/) - Multi-cluster definitions Multi-OCI (examples/multi-oci/) - Multi-source OCI deployments",
    "description": "Examples Practical examples of using Kure to generate Kubernetes configurations.\nMounted Examples These examples include full documentation:\nPatches - Declarative patching with TOML and YAML formats Generators - Resource generation using the GVK system Kurel Frigate - Building a complete kurel package Validation - Resource validation patterns Additional Examples These examples are available in the examples/ directory on GitHub:\nApp Workloads (examples/appworkloads/) - Application workload generation Bootstrap (examples/bootstrap/) - Flux bootstrap configuration Clusters (examples/clusters/) - Multi-cluster definitions Multi-OCI (examples/multi-oci/) - Multi-source OCI deployments",
    "tags": [],
    "title": "Examples",
    "uri": "/examples/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Layout Module The layout module is a sophisticated system for organizing and writing Kubernetes manifests to disk in directory structures that work with GitOps tools like Flux and ArgoCD.\nCore Purpose The layout module transforms Kure’s in-memory stack representation (Clusters → Nodes → Bundles → Applications) into organized directory structures with proper kustomization.yaml files that GitOps tools can consume.\nKey Components 1. ManifestLayout Structure Central data structure representing a directory with its resources and children Contains: Name, Namespace, Resources (K8s objects), Children (subdirectories) Supports package-aware layouts for multi-OCI/Git scenarios 2. LayoutRules Configuration NodeGrouping: How nodes are organized (GroupByName creates dirs, GroupFlat flattens) BundleGrouping: How bundles within nodes are organized ApplicationGrouping: How applications within bundles are organized FilePer: How resources are written (FilePerResource vs FilePerKind) FluxPlacement: Where Flux Kustomizations go (FluxSeparate vs FluxIntegrated) 3. Two Main Walker Functions WalkCluster(): Standard hierarchical layout (Node → Bundle → App structure) WalkClusterByPackage(): Groups by PackageRef for multi-source scenarios 4. Writing System WriteManifest(): Standard hierarchical writing WritePackagesToDisk(): Package-based writing with sanitized directory names Auto-generates kustomization.yaml files with proper resource references Directory Structure Patterns Standard Layout (WalkCluster) clusters/ cluster-name/ node1/ bundle1/ app1/ manifest-files.yaml kustomization.yaml app2/... bundle2/... node2/... Package-Based Layout (WalkClusterByPackage) oci-packages/ cluster/ web/ app-manifests.yaml git-packages/ cluster/ monitoring/ app-manifests.yaml Flat Layout (GroupFlat rules) clusters/ cluster-name/ all-manifests-together.yaml kustomization.yaml GitOps Tool Compatibility Flux Integration Uses spec.path: ./clusters/cluster-name/node format Auto-generates kustomization.yaml files Supports recursive discovery of manifests Handles FluxSeparate vs FluxIntegrated placement modes ArgoCD Integration Uses spec.source.path: clusters/cluster-name/node format Requires explicit kustomization.yaml files (no auto-discovery) Each target directory needs its own Application Advanced Features Package Reference Support Tracks different source types (OCIRepository, GitRepository, Bucket) Enables multi-source deployments with proper isolation Sanitizes package keys into valid directory names Flexible File Organization FilePerResource: Each K8s object gets its own file FilePerKind: Group objects by Kind (all Services together, etc.) AppFileSingle: All app resources in one file Kustomization Generation KustomizationExplicit: Lists all manifest files explicitly KustomizationRecursive: References subdirectories only Smart handling of cross-references and child relationships Real-World Use Cases Simple Cluster: Single source, hierarchical structure Multi-OCI Deployment: Different services from different OCI registries Monorepo: Everything flattened into minimal directory structure Bootstrap Scenarios: Special handling for Flux/ArgoCD system components Example Usage // Create layout rules rules := layout.DefaultLayoutRules() rules.BundleGrouping = layout.GroupFlat rules.ApplicationGrouping = layout.GroupFlat // Walk cluster to create layout ml, err := layout.WalkCluster(cluster, rules) if err != nil { return err } // Write to disk cfg := layout.DefaultLayoutConfig() err = layout.WriteManifest(\"out/manifests\", cfg, ml) Key Files types.go: Core types and configuration options walker.go: Tree traversal algorithms (WalkCluster, WalkClusterByPackage) manifest.go: ManifestLayout structure and package-based writing write.go: Standard manifest writing with kustomization generation config.go: Configuration and file naming conventions The layout module essentially bridges the gap between Kure’s programmatic resource construction and the file-based expectations of GitOps workflows, with extensive configurability for different organizational preferences and tool requirements.",
    "description": "Layout Module The layout module is a sophisticated system for organizing and writing Kubernetes manifests to disk in directory structures that work with GitOps tools like Flux and ArgoCD.\nCore Purpose The layout module transforms Kure’s in-memory stack representation (Clusters → Nodes → Bundles → Applications) into organized directory structures with proper kustomization.yaml files that GitOps tools can consume.\nKey Components 1. ManifestLayout Structure Central data structure representing a directory with its resources and children Contains: Name, Namespace, Resources (K8s objects), Children (subdirectories) Supports package-aware layouts for multi-OCI/Git scenarios 2. LayoutRules Configuration NodeGrouping: How nodes are organized (GroupByName creates dirs, GroupFlat flattens) BundleGrouping: How bundles within nodes are organized ApplicationGrouping: How applications within bundles are organized FilePer: How resources are written (FilePerResource vs FilePerKind) FluxPlacement: Where Flux Kustomizations go (FluxSeparate vs FluxIntegrated) 3. Two Main Walker Functions WalkCluster(): Standard hierarchical layout (Node → Bundle → App structure) WalkClusterByPackage(): Groups by PackageRef for multi-source scenarios 4. Writing System WriteManifest(): Standard hierarchical writing WritePackagesToDisk(): Package-based writing with sanitized directory names Auto-generates kustomization.yaml files with proper resource references Directory Structure Patterns Standard Layout (WalkCluster) clusters/ cluster-name/ node1/ bundle1/ app1/ manifest-files.yaml kustomization.yaml app2/... bundle2/... node2/... Package-Based Layout (WalkClusterByPackage) oci-packages/ cluster/ web/ app-manifests.yaml git-packages/ cluster/ monitoring/ app-manifests.yaml Flat Layout (GroupFlat rules) clusters/ cluster-name/ all-manifests-together.yaml kustomization.yaml GitOps Tool Compatibility Flux Integration Uses spec.path: ./clusters/cluster-name/node format Auto-generates kustomization.yaml files Supports recursive discovery of manifests Handles FluxSeparate vs FluxIntegrated placement modes ArgoCD Integration Uses spec.source.path: clusters/cluster-name/node format Requires explicit kustomization.yaml files (no auto-discovery) Each target directory needs its own Application Advanced Features Package Reference Support Tracks different source types (OCIRepository, GitRepository, Bucket) Enables multi-source deployments with proper isolation Sanitizes package keys into valid directory names Flexible File Organization FilePerResource: Each K8s object gets its own file FilePerKind: Group objects by Kind (all Services together, etc.) AppFileSingle: All app resources in one file Kustomization Generation KustomizationExplicit: Lists all manifest files explicitly KustomizationRecursive: References subdirectories only Smart handling of cross-references and child relationships Real-World Use Cases Simple Cluster: Single source, hierarchical structure Multi-OCI Deployment: Different services from different OCI registries Monorepo: Everything flattened into minimal directory structure Bootstrap Scenarios: Special handling for Flux/ArgoCD system components Example Usage // Create layout rules rules := layout.DefaultLayoutRules() rules.BundleGrouping = layout.GroupFlat rules.ApplicationGrouping = layout.GroupFlat // Walk cluster to create layout ml, err := layout.WalkCluster(cluster, rules) if err != nil { return err } // Write to disk cfg := layout.DefaultLayoutConfig() err = layout.WriteManifest(\"out/manifests\", cfg, ml) Key Files types.go: Core types and configuration options walker.go: Tree traversal algorithms (WalkCluster, WalkClusterByPackage) manifest.go: ManifestLayout structure and package-based writing write.go: Standard manifest writing with kustomization generation config.go: Configuration and file naming conventions The layout module essentially bridges the gap between Kure’s programmatic resource construction and the file-based expectations of GitOps workflows, with extensive configurability for different organizational preferences and tool requirements.",
    "tags": [],
    "title": "Layout Engine",
    "uri": "/api-reference/layout/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Guides",
    "content": "Patching Resources Kure’s patch system lets you declaratively modify Kubernetes resources using JSONPath expressions. Patches are applied after resource generation, making them useful for environment-specific customization.\nWhen to Patch vs Configure Configure at generation time when you control the resource builder (set replicas, image, etc. in code) Patch after generation when you need to modify resources from external sources, or when the same base resources need different modifications per environment Patch File Formats TOML Format (.kpatch) The TOML format uses section headers to target resources:\n# [kind.name.path.to.field] [deployment.myapp.spec] replicas = 3 [deployment.myapp.spec.template.spec.containers.0] image = \"nginx:1.25\" resources.requests.cpu = \"200m\" resources.requests.memory = \"256Mi\" YAML Format target: kind: Deployment name: myapp patches: - path: spec.replicas value: 3 - path: spec.template.spec.containers[0].image value: \"nginx:1.25\" Applying Patches import \"github.com/go-kure/kure/pkg/patch\" // Load patches from file file, _ := os.Open(\"patches/production.kpatch\") specs, err := patch.LoadPatchFile(file) // Create patchable set patchSet, err := patch.NewPatchableAppSet(resources, specs) // Resolve and apply resolved, err := patchSet.Resolve() for _, r := range resolved { err := r.Apply() } // Write output err = patchSet.WriteToFile(\"patched-output.yaml\") Variable Substitution Patches can reference variables:\n[deployment.myapp.spec.template.spec.containers.0] image = \"${registry}/${image}:${tag}\" varCtx := \u0026patch.VariableContext{ Variables: map[string]interface{}{ \"registry\": \"docker.io\", \"image\": \"myapp\", \"tag\": \"v2.0.0\", }, } specs, err := patch.LoadPatchFileWithVariables(file, varCtx) List Operations Target by index [deployment.myapp.spec.template.spec.containers.0] image = \"updated:latest\" Append to list [deployment.myapp.spec.template.spec.containers.-] name = \"sidecar\" image = \"envoy:latest\" Target by field selector [deployment.myapp.spec.template.spec.containers.{name=myapp}] image = \"updated:latest\" Strategic Merge Patch For broad document-level changes, use strategic merge patch (SMP). Instead of targeting individual fields, SMP deep-merges a partial YAML document into the target resource.\nHow It Works Known Kubernetes kinds (Deployment, Service, etc.) are merged using struct tags — lists like containers are merged by name, not replaced. Unknown kinds (CRDs) fall back to JSON merge patch (RFC 7386), where lists are replaced entirely.\nYAML Syntax # Add a sidecar and update the main container's resources - target: deployment.my-app type: strategic patch: spec: template: spec: containers: - name: main resources: limits: cpu: \"500m\" memory: \"256Mi\" - name: sidecar image: envoy:v1.28 Mixing with Field-Level Patches SMP and field-level patches can coexist in the same file. SMP patches are applied first (setting the document shape), then field-level patches make precise tweaks:\n# Strategic merge: add a sidecar container - target: deployment.my-app type: strategic patch: spec: template: spec: containers: - name: sidecar image: envoy:v1.28 # Field-level: set replica count precisely - target: deployment.my-app patch: spec.replicas: 3 Enabling Kind-Aware Merging import \"github.com/go-kure/kure/pkg/patch\" // Create a kind lookup for schema-aware merging lookup, err := patch.DefaultKindLookup() patchSet.KindLookup = lookup Conflict Detection When multiple SMP patches target the same resource, check for conflicts:\nresolved, reports, err := patchSet.ResolveWithConflictCheck() for _, r := range reports { if r.HasConflicts() { for _, c := range r.Conflicts { log.Printf(\"conflict on %s: %s\", r.ResourceName, c.Description) } } } Further Reading Patch reference for API details Patch examples for working samples Kurel packages for patch-based package customization",
    "description": "Patching Resources Kure’s patch system lets you declaratively modify Kubernetes resources using JSONPath expressions. Patches are applied after resource generation, making them useful for environment-specific customization.\nWhen to Patch vs Configure Configure at generation time when you control the resource builder (set replicas, image, etc. in code) Patch after generation when you need to modify resources from external sources, or when the same base resources need different modifications per environment Patch File Formats TOML Format (.kpatch) The TOML format uses section headers to target resources:",
    "tags": [],
    "title": "Patching Resources",
    "uri": "/guides/patching/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Examples",
    "content": "Validation Examples This directory contains examples demonstrating Kure’s built-in validation features.\nBundle Interval Validation File: bundle-intervals.yaml\nDemonstrates proper configuration of time interval fields in Bundle resources:\nValid Examples: Recommended patterns and edge cases Invalid Examples: Common mistakes and validation errors (commented out) Error Messages: Examples of validation error output Key Validation Rules Format: Go time.Duration syntax (1s, 5m, 1h, 1h30m) Range: 1 second minimum, 24 hours maximum Fields: interval, timeout, retryInterval Best Practices Reconciliation: Use 5m to 30m for most applications Timeouts: Set 2-3x longer than expected deployment time Retry Intervals: Use 1m to 5m for faster failure recovery Production: Avoid very short intervals (\u003c1m) to reduce API load Testing Validation To test validation with these examples:\n# This will validate the YAML and show any errors kure validate examples/validation/bundle-intervals.yaml # Or test programmatically go run examples/validation/test-validation.go For more information, see the main README.md validation section.",
    "description": "Validation Examples This directory contains examples demonstrating Kure’s built-in validation features.\nBundle Interval Validation File: bundle-intervals.yaml\nDemonstrates proper configuration of time interval fields in Bundle resources:\nValid Examples: Recommended patterns and edge cases Invalid Examples: Common mistakes and validation errors (commented out) Error Messages: Examples of validation error output Key Validation Rules Format: Go time.Duration syntax (1s, 5m, 1h, 1h30m) Range: 1 second minimum, 24 hours maximum Fields: interval, timeout, retryInterval Best Practices Reconciliation: Use 5m to 30m for most applications Timeouts: Set 2-3x longer than expected deployment time Retry Intervals: Use 1m to 5m for faster failure recovery Production: Avoid very short intervals (\u003c1m) to reduce API load Testing Validation To test validation with these examples:",
    "tags": [],
    "title": "Validation",
    "uri": "/examples/validation/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e Guides",
    "content": "Building Kurel Packages Kurel is the package system for creating reusable Kubernetes applications. A kurel package bundles base manifests, patches, and parameters into a self-contained unit that can be customized per deployment.\nPackage Structure my-app.kurel/ ├── parameters.yaml # Variables and package metadata ├── resources/ # Base Kubernetes manifests │ ├── deployment.yaml │ ├── service.yaml │ └── namespace.yaml ├── patches/ # Modular customization patches │ ├── 00-base.kpatch # Global settings │ ├── features/ │ │ ├── 10-monitoring.kpatch │ │ └── 10-monitoring.yaml # Patch conditions │ └── profiles/ │ ├── 10-dev.kpatch │ └── 20-prod.kpatch └── README.md Creating a Package 1. Define Parameters # parameters.yaml kurel: name: my-application version: 1.0.0 description: \"A sample application package\" app: replicas: 3 image: repository: myapp tag: v1.0.0 monitoring: enabled: false 2. Add Base Resources Place standard Kubernetes manifests in resources/. These are the starting point before patches are applied.\n3. Write Patches Patches customize the base resources. See the Patching guide for the TOML patch format.\n4. Add Conditional Patches Control when patches are applied:\n# patches/features/10-monitoring.yaml enabled: \"${monitoring.enabled}\" description: \"Adds Prometheus monitoring\" requires: - \"features/05-metrics-base.kpatch\" Building and Deploying # Validate the package kurel validate my-app.kurel/ # Build with custom values kurel build my-app.kurel/ \\ --values production.yaml \\ --output ./manifests/ # Show package information kurel info my-app.kurel/ Multi-Phase Deployment Annotate resources to control deployment ordering:\nmetadata: annotations: kurel.gokure.dev/install-phase: \"pre-install\" # or \"main\", \"post-install\" This generates separate phase directories with proper dependencies for GitOps deployment.\nUser Extensions Extend packages without modifying them using .local.kurel:\nmy-app.local.kurel/ ├── parameters.yaml # Override parameters └── patches/ └── 50-custom.kpatch # Add custom patches Further Reading Launcher reference for the package system API Kurel Frigate example for a complete package Patching guide for the patch format",
    "description": "Building Kurel Packages Kurel is the package system for creating reusable Kubernetes applications. A kurel package bundles base manifests, patches, and parameters into a self-contained unit that can be customized per deployment.\nPackage Structure my-app.kurel/ ├── parameters.yaml # Variables and package metadata ├── resources/ # Base Kubernetes manifests │ ├── deployment.yaml │ ├── service.yaml │ └── namespace.yaml ├── patches/ # Modular customization patches │ ├── 00-base.kpatch # Global settings │ ├── features/ │ │ ├── 10-monitoring.kpatch │ │ └── 10-monitoring.yaml # Patch conditions │ └── profiles/ │ ├── 10-dev.kpatch │ └── 20-prod.kpatch └── README.md Creating a Package 1. Define Parameters # parameters.yaml kurel: name: my-application version: 1.0.0 description: \"A sample application package\" app: replicas: 3 image: repository: myapp tag: v1.0.0 monitoring: enabled: false 2. Add Base Resources Place standard Kubernetes manifests in resources/. These are the starting point before patches are applied.",
    "tags": [],
    "title": "Building Kurel Packages",
    "uri": "/guides/kurel-packages/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "CLI Reference Kure provides two command-line tools.\nkure The main CLI for Kubernetes resource generation.\nkure [command] [flags] Commands Command Description generate Generate Kubernetes resources from configuration patch Apply patches to existing manifests validate Validate resource configurations config Manage kure configuration version Print version information completion Generate shell completion scripts kurel The package system CLI for building and managing reusable application packages.\nkurel [command] [flags] Commands Command Description build Build Kubernetes manifests from a kurel package validate Validate kurel package structure and configuration info Show package information schema Schema generation and validation commands config Manage kurel configuration version Print version information completion Generate shell completion scripts kurel build kurel build \u003cpackage\u003e [flags] Flag Description -o, --output Output path (default: stdout) --values Values file for parameter overrides -p, --patch Enable specific patches --format Output format: yaml, json (default: yaml) --kind Filter by resource kind --name Filter by resource name --add-label Add labels to all resources kurel validate kurel validate \u003cpackage\u003e [flags] Flag Description --values Values file for validation --schema Custom schema file --json Output validation results as JSON kurel info kurel info \u003cpackage\u003e [flags] Flag Description -o, --output Output format: text, yaml, json (default: text) --all Show all details including resource content Global Flags Both tools support:\nFlag Description -v, --verbose Enable verbose output --debug Enable debug mode --strict Enable strict validation --config Configuration file path",
    "description": "CLI Reference Kure provides two command-line tools.\nkure The main CLI for Kubernetes resource generation.\nkure [command] [flags] Commands Command Description generate Generate Kubernetes resources from configuration patch Apply patches to existing manifests validate Validate resource configurations config Manage kure configuration version Print version information completion Generate shell completion scripts kurel The package system CLI for building and managing reusable application packages.\nkurel [command] [flags] Commands Command Description build Build Kubernetes manifests from a kurel package validate Validate kurel package structure and configuration info Show package information schema Schema generation and validation commands config Manage kurel configuration version Print version information completion Generate shell completion scripts kurel build kurel build \u003cpackage\u003e [flags] Flag Description -o, --output Output path (default: stdout) --values Values file for parameter overrides -p, --patch Enable specific patches --format Output format: yaml, json (default: yaml) --kind Filter by resource kind --name Filter by resource name --add-label Add labels to all resources kurel validate kurel validate \u003cpackage\u003e [flags] Flag Description --values Values file for validation --schema Custom schema file --json Output validation results as JSON kurel info kurel info \u003cpackage\u003e [flags] Flag Description -o, --output Output format: text, yaml, json (default: text) --all Show all details including resource content Global Flags Both tools support:",
    "tags": [],
    "title": "CLI Reference",
    "uri": "/cli-reference/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Launcher - Kubernetes Resources Launcher This package provides the core functionality for Kurel, the Kubernetes Resources Launcher CLI tool.\nKurel is a package system for creating reusable, customizable Kubernetes applications without the complexity of templating engines. It uses a declarative patch-based approach to customize base Kubernetes manifests, making it perfect for GitOps workflows.\n✨ Key Features 📦 Package-based - Encapsulate applications in reusable .kurel packages 🎯 No Templating - Use patches instead of complex template syntax 🔧 Declarative Customization - Simple parameter-driven configuration 🚀 GitOps Native - Generate clean Kubernetes manifests for Flux/ArgoCD 📊 Schema Validation - Auto-generated schemas with Kubernetes API integration 🏗️ Multi-Phase Deployment - Support for ordered deployment phases 🌐 Multi-Namespace - Deploy across multiple namespaces seamlessly 🎨 User Extensions - Extend packages without modifying originals 🚀 Quick Start Installing a Package # Download a kurel package (example) git clone https://github.com/example/prometheus-operator.kurel # Validate the package kurel validate prometheus-operator.kurel/ # Customize with your parameters cat \u003e my-values.yaml \u003c\u003c EOF monitoring: enabled: true retention: 7d persistence: enabled: true size: 50Gi resources: requests: cpu: 200m memory: 512Mi EOF # Generate manifests kurel build prometheus-operator.kurel/ \\ --values my-values.yaml \\ --output ./manifests/ Using with GitOps # Generated structure is GitOps-ready ls manifests/ # pre-install/ - CRDs, namespaces, RBAC # main/ - Main application (depends on pre-install) # post-install/ - Monitoring, backups (depends on main) # Each phase includes kustomization.yaml with proper dependencies cat manifests/main/kustomization.yaml # apiVersion: kustomize.config.k8s.io/v1beta1 # kind: Kustomization # dependsOn: # - name: prometheus-pre-install # resources: [...] 📁 Package Structure A kurel package is a directory with this structure:\nmy-app.kurel/ ├── parameters.yaml # Variables and package metadata ├── resources/ # Base Kubernetes manifests │ ├── deployment.yaml │ ├── service.yaml │ └── namespace.yaml ├── patches/ # Modular customization patches │ ├── 00-base.kpatch # Global settings │ ├── features/ │ │ ├── 10-monitoring.kpatch │ │ ├── 10-monitoring.yaml # Patch conditions │ │ └── 20-ingress.kpatch │ └── profiles/ │ ├── 10-dev.kpatch │ └── 20-prod.kpatch └── README.md # Package documentation ⚙️ Configuration Parameters File The parameters.yaml file contains all configurable options:\n# Package metadata kurel: name: my-application version: 1.0.0 description: \"A sample application package\" # Global defaults applied to all resources global: labels: app.kubernetes.io/managed-by: kurel resources: requests: cpu: 100m memory: 128Mi # Feature flags monitoring: enabled: false # Enable monitoring patches retention: 30d # Application settings app: replicas: 3 image: registry: docker.io repository: myapp tag: v1.0.0 Patch System Patches use simple TOML syntax to modify resources:\n# patches/features/10-monitoring.kpatch [deployment.myapp.spec.template.spec] securityContext.runAsNonRoot: true [deployment.myapp.spec.template.spec.containers.0] resources: \"${global.resources}\" image: \"${app.image.registry}/${app.image.repository}:${app.image.tag}\" # Add monitoring sidecar [deployment.myapp.spec.template.spec.containers.-] name: \"metrics-exporter\" image: \"prom/node-exporter:latest\" ports: - containerPort: 9100 name: \"metrics\" Conditional Patches Control when patches are applied:\n# patches/features/10-monitoring.yaml enabled: \"${monitoring.enabled}\" # Only apply if monitoring enabled description: \"Adds Prometheus monitoring\" requires: # Auto-enable these patches - \"features/05-metrics-base.kpatch\" conflicts: # Cannot be used with these - \"features/20-simple-monitoring.kpatch\" 🔧 User Customization Local Extensions Extend packages without modifying them using .local.kurel:\nmy-app.local.kurel/ ├── parameters.yaml # Override parameters └── patches/ └── 50-custom.kpatch # Add custom patches Example Local Override # my-app.local.kurel/parameters.yaml monitoring: enabled: true # Enable monitoring retention: 7d # Shorter retention app: replicas: 5 # More replicas for production 🏗️ Multi-Phase Deployment Support complex applications that need ordered deployment:\n# In your Kubernetes resources apiVersion: v1 kind: Namespace metadata: name: myapp annotations: kurel.gokure.dev/install-phase: \"pre-install\" --- apiVersion: apps/v1 kind: Deployment metadata: name: myapp-server annotations: kurel.gokure.dev/install-phase: \"main\" --- apiVersion: v1 kind: Service metadata: name: myapp-monitor annotations: kurel.gokure.dev/install-phase: \"post-install\" This generates three separate phases with proper dependencies for GitOps deployment.\n🛠️ CLI Commands Validation # Validate package structure and parameters kurel validate my-app.kurel/ --values my-values.yaml # Output shows enabled patches and validation results # ✓ Package structure valid # ✓ All variables resolved # Enabled patches: # ✓ patches/00-base.kpatch # ✓ patches/features/10-monitoring.kpatch (monitoring.enabled=true) # → patches/features/05-metrics-base.kpatch (auto-enabled) Schema Generation # Generate validation schemas kurel schema generate my-app.kurel/ # Creates schemas/parameters.schema.json with: # - Type information from parameter values # - Kubernetes validation rules where traceable # - Custom validation patterns Building Manifests # Generate final Kubernetes manifests kurel build my-app.kurel/ \\ --values production.yaml \\ --output ./deploy/ # Generates phase-based directory structure: # deploy/pre-install/ - CRDs, namespaces, RBAC # deploy/main/ - Main application # deploy/post-install/ - Monitoring, cleanup Package Information # Show package details kurel info my-app.kurel/ # Package: my-application v1.0.0 # Description: A sample application package # Patches: 8 total, 3 conditional # Variables: 12 configurable parameters # Phases: pre-install, main, post-install 🌟 Common Use Cases Platform Teams Create standardized application packages with defined customization boundaries:\n# Standard web app package kurel: name: webapp-standard version: 2.1.0 global: securityContext: runAsNonRoot: true fsGroup: 1000 # Teams can only customize these parameters app: replicas: 3 domain: \"\" # Required override monitoring: enabled: true # Always enabled for compliance Multi-Environment Deployments Same package, different configurations:\n# Development kurel build webapp.kurel/ --values environments/dev.yaml # Staging kurel build webapp.kurel/ --values environments/staging.yaml # Production kurel build webapp.kurel/ --values environments/prod.yaml Complex Applications Multi-namespace applications with dependencies:\n# Database in its own namespace (pre-install) # Application in app namespace (main) # Monitoring in monitoring namespace (post-install) global: namespaces: create: true database: namespace: database app: namespace: application monitoring: namespace: monitoring 🤝 Contributing Kurel is part of the Kure project. See the main repository for contribution guidelines.\n📚 Documentation Design Specification - Technical design and architecture Detailed Design Document - Complete design discussion and decisions Kure Documentation - Main project documentation 🎯 Philosophy Kurel follows the principle “kurel just generates YAML”. It’s not a runtime system or complex orchestrator - it’s a focused tool that generates clean, validated Kubernetes manifests for your GitOps workflows.\nThis approach gives you:\nPredictable output - Same inputs always generate same manifests GitOps compatibility - Standard Kubernetes YAML that any tool can deploy Debugging simplicity - Generated manifests are human-readable Tool independence - Not locked into specific deployment tools",
    "description": "Launcher - Kubernetes Resources Launcher This package provides the core functionality for Kurel, the Kubernetes Resources Launcher CLI tool.\nKurel is a package system for creating reusable, customizable Kubernetes applications without the complexity of templating engines. It uses a declarative patch-based approach to customize base Kubernetes manifests, making it perfect for GitOps workflows.\n✨ Key Features 📦 Package-based - Encapsulate applications in reusable .kurel packages 🎯 No Templating - Use patches instead of complex template syntax 🔧 Declarative Customization - Simple parameter-driven configuration 🚀 GitOps Native - Generate clean Kubernetes manifests for Flux/ArgoCD 📊 Schema Validation - Auto-generated schemas with Kubernetes API integration 🏗️ Multi-Phase Deployment - Support for ordered deployment phases 🌐 Multi-Namespace - Deploy across multiple namespaces seamlessly 🎨 User Extensions - Extend packages without modifying originals 🚀 Quick Start Installing a Package # Download a kurel package (example) git clone https://github.com/example/prometheus-operator.kurel # Validate the package kurel validate prometheus-operator.kurel/ # Customize with your parameters cat \u003e my-values.yaml \u003c\u003c EOF monitoring: enabled: true retention: 7d persistence: enabled: true size: 50Gi resources: requests: cpu: 200m memory: 512Mi EOF # Generate manifests kurel build prometheus-operator.kurel/ \\ --values my-values.yaml \\ --output ./manifests/ Using with GitOps # Generated structure is GitOps-ready ls manifests/ # pre-install/ - CRDs, namespaces, RBAC # main/ - Main application (depends on pre-install) # post-install/ - Monitoring, backups (depends on main) # Each phase includes kustomization.yaml with proper dependencies cat manifests/main/kustomization.yaml # apiVersion: kustomize.config.k8s.io/v1beta1 # kind: Kustomization # dependsOn: # - name: prometheus-pre-install # resources: [...] 📁 Package Structure A kurel package is a directory with this structure:",
    "tags": [],
    "title": "Launcher",
    "uri": "/api-reference/launcher/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "API Reference Kure’s public API is organized into focused packages. Each package README below is auto-synced from the source code.\nFor full Go API documentation, see pkg.go.dev/github.com/go-kure/kure .\nCore Domain Package Description Reference Stack Cluster, Node, Bundle, Application domain model pkg.go.dev Flux Engine FluxCD workflow implementation pkg.go.dev Generators Application generator system (GVK) pkg.go.dev Layout Engine Manifest directory organization pkg.go.dev Package System Package Description Reference Launcher Kurel package loading, building, validation pkg.go.dev Resource Operations Package Description Reference Patch JSONPath-based declarative patching pkg.go.dev IO YAML/JSON serialization and resource printing pkg.go.dev Kubernetes Builders Core K8s resource constructors (GVK, HPA, PDB) pkg.go.dev FluxCD Builders Low-level Flux resource constructors pkg.go.dev Utilities Package Description Reference Errors Structured error types pkg.go.dev CLI Utilities Factory, IOStreams, Printer pkg.go.dev Logger Structured logging pkg.go.dev Compatibility Compatibility Matrix - Supported Kubernetes and dependency versions ArgoCD ArgoCD support exists at pkg/stack/argocd/ but is not yet production-ready. It is not featured in guides or examples. The Flux workflow is the primary supported GitOps integration.",
    "description": "API Reference Kure’s public API is organized into focused packages. Each package README below is auto-synced from the source code.\nFor full Go API documentation, see pkg.go.dev/github.com/go-kure/kure .\nCore Domain Package Description Reference Stack Cluster, Node, Bundle, Application domain model pkg.go.dev Flux Engine FluxCD workflow implementation pkg.go.dev Generators Application generator system (GVK) pkg.go.dev Layout Engine Manifest directory organization pkg.go.dev Package System Package Description Reference Launcher Kurel package loading, building, validation pkg.go.dev Resource Operations Package Description Reference Patch JSONPath-based declarative patching pkg.go.dev IO YAML/JSON serialization and resource printing pkg.go.dev Kubernetes Builders Core K8s resource constructors (GVK, HPA, PDB) pkg.go.dev FluxCD Builders Low-level Flux resource constructors pkg.go.dev Utilities Package Description Reference Errors Structured error types pkg.go.dev CLI Utilities Factory, IOStreams, Printer pkg.go.dev Logger Structured logging pkg.go.dev Compatibility Compatibility Matrix - Supported Kubernetes and dependency versions ArgoCD ArgoCD support exists at pkg/stack/argocd/ but is not yet production-ready. It is not featured in guides or examples. The Flux workflow is the primary supported GitOps integration.",
    "tags": [],
    "title": "API Reference",
    "uri": "/api-reference/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Patch - Declarative Resource Patching The patch package provides a JSONPath-based system for declaratively modifying Kubernetes resources. It supports both TOML and YAML patch file formats with structure-preserving modifications and variable substitution.\nOverview Patches allow you to modify Kubernetes manifests without rewriting them. The system uses JSONPath expressions to target specific fields and applies changes while preserving the original YAML structure (comments, ordering, formatting).\nPatch File Formats TOML Format (.kpatch) # Target a specific resource by kind and name [deployment.myapp.spec] replicas = 3 [deployment.myapp.spec.template.spec.containers.0] image = \"${app.image}:${app.tag}\" resources.requests.cpu = \"200m\" resources.requests.memory = \"256Mi\" # Append to a list with .- [deployment.myapp.spec.template.spec.containers.-] name = \"sidecar\" image = \"envoy:latest\" YAML Format target: kind: Deployment name: myapp patches: - path: spec.replicas value: 3 - path: spec.template.spec.containers[0].image value: \"nginx:latest\" Quick Start import \"github.com/go-kure/kure/pkg/patch\" // Load patches from file file, _ := os.Open(\"patches/customize.kpatch\") specs, err := patch.LoadPatchFile(file) // Create patchable set with resources and patches patchSet, err := patch.NewPatchableAppSet(resources, specs) // Resolve targets and apply resolved, err := patchSet.Resolve() for _, r := range resolved { err := r.Apply() } // Write patched output err = patchSet.WriteToFile(\"output.yaml\") Key Features Variable Substitution Patches support variable references that resolve against a parameter context:\n[deployment.myapp.spec.template.spec.containers.0] image = \"${registry}/${image}:${tag}\" replicas = \"${replicas}\" varCtx := \u0026patch.VariableContext{ Variables: map[string]interface{}{ \"registry\": \"docker.io\", \"image\": \"myapp\", \"tag\": \"v1.0.0\", \"replicas\": 3, }, } specs, err := patch.LoadPatchFileWithVariables(file, varCtx) List Selectors Target specific items in lists using selectors:\n# By index [deployment.myapp.spec.template.spec.containers.0] image = \"updated:latest\" # Append to list [deployment.myapp.spec.template.spec.containers.-] name = \"new-container\" # By field value (name selector) [deployment.myapp.spec.template.spec.containers.{name=myapp}] image = \"updated:latest\" Structure Preservation When using NewPatchableAppSetWithStructure, the original YAML document structure is preserved through patching, maintaining comments, key ordering, and formatting.\nStrategic Merge Patch For broad document-level changes, strategic merge patch (SMP) deep-merges a partial YAML document into the target resource. Known Kubernetes kinds merge lists by key (e.g. containers by name); unknown kinds fall back to JSON merge patch (RFC 7386).\n- target: deployment.my-app type: strategic patch: spec: template: spec: containers: - name: main resources: limits: cpu: \"500m\" - name: sidecar image: envoy:v1.28 // Enable kind-aware merging lookup, _ := patch.DefaultKindLookup() patchSet.KindLookup = lookup // Detect conflicts before applying resolved, reports, err := patchSet.ResolveWithConflictCheck() SMP patches are applied before field-level patches. See DESIGN.md for full specification.\nAPI Reference Loading Patches Function Description LoadPatchFile(r) Load with automatic format detection LoadPatchFileWithVariables(r, ctx) Load with variable substitution LoadTOMLPatchFile(r, ctx) Load TOML-format patches LoadYAMLPatchFile(r, ctx) Load YAML-format patches Applying Patches Function Description NewPatchableAppSet(resources, patches) Create patchable set NewPatchableAppSetWithStructure(docSet, patches) Create with structure preservation ParsePatchLine(path, value) Parse a single patch operation Strategic Merge Patch Function Description ApplyStrategicMergePatch(resource, patch, lookup) Apply SMP to a single resource DefaultKindLookup() Create a KindLookup from the built-in scheme DetectSMPConflicts(patches, lookup, gvk) Check pairwise conflicts among patches ResolveWithConflictCheck() Resolve patches with conflict detection Related Packages launcher - Uses patches in kurel package system io - YAML parsing for patch targets",
    "description": "Patch - Declarative Resource Patching The patch package provides a JSONPath-based system for declaratively modifying Kubernetes resources. It supports both TOML and YAML patch file formats with structure-preserving modifications and variable substitution.\nOverview Patches allow you to modify Kubernetes manifests without rewriting them. The system uses JSONPath expressions to target specific fields and applies changes while preserving the original YAML structure (comments, ordering, formatting).\nPatch File Formats TOML Format (.kpatch) # Target a specific resource by kind and name [deployment.myapp.spec] replicas = 3 [deployment.myapp.spec.template.spec.containers.0] image = \"${app.image}:${app.tag}\" resources.requests.cpu = \"200m\" resources.requests.memory = \"256Mi\" # Append to a list with .- [deployment.myapp.spec.template.spec.containers.-] name = \"sidecar\" image = \"envoy:latest\" YAML Format target: kind: Deployment name: myapp patches: - path: spec.replicas value: 3 - path: spec.template.spec.containers[0].image value: \"nginx:latest\" Quick Start import \"github.com/go-kure/kure/pkg/patch\" // Load patches from file file, _ := os.Open(\"patches/customize.kpatch\") specs, err := patch.LoadPatchFile(file) // Create patchable set with resources and patches patchSet, err := patch.NewPatchableAppSet(resources, specs) // Resolve targets and apply resolved, err := patchSet.Resolve() for _, r := range resolved { err := r.Apply() } // Write patched output err = patchSet.WriteToFile(\"output.yaml\") Key Features Variable Substitution Patches support variable references that resolve against a parameter context:",
    "tags": [],
    "title": "Patch",
    "uri": "/api-reference/patch/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Changelog Track changes across Kure releases.\nReleases - Version history and release notes",
    "description": "Changelog Track changes across Kure releases.\nReleases - Version history and release notes",
    "tags": [],
    "title": "Changelog",
    "uri": "/changelog/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "Contributing Resources for contributing to Kure.\nDevelopment Guide - Setup, testing, code quality, and CI/CD workflows GitHub Workflows - CI/CD pipeline documentation Quick Start # Clone the repository git clone https://github.com/go-kure/kure.git cd kure # Install tools make tools # Run checks make check # Run full pre-commit validation make precommit Branch Workflow main is protected. Create a feature branch:\ngit checkout -b feat/my-feature main # make changes git push -u origin feat/my-feature gh pr create Required CI checks: lint, test, build.",
    "description": "Contributing Resources for contributing to Kure.\nDevelopment Guide - Setup, testing, code quality, and CI/CD workflows GitHub Workflows - CI/CD pipeline documentation Quick Start # Clone the repository git clone https://github.com/go-kure/kure.git cd kure # Install tools make tools # Run checks make check # Run full pre-commit validation make precommit Branch Workflow main is protected. Create a feature branch:\ngit checkout -b feat/my-feature main # make changes git push -u origin feat/my-feature gh pr create Required CI checks: lint, test, build.",
    "tags": [],
    "title": "Contributing",
    "uri": "/contributing/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "IO - YAML Serialization and Resource Printing The io package provides utilities for parsing, serializing, and printing Kubernetes resources. It supports multiple output formats including YAML, JSON, and kubectl-compatible table views.\nOverview This package handles the I/O boundary of Kure: reading Kubernetes manifests from files, serializing resources to YAML/JSON, and printing resources in human-readable formats. It integrates with Kure’s registered scheme for type-aware parsing.\nParsing Parse YAML Files import \"github.com/go-kure/kure/pkg/io\" // Parse a multi-document YAML file into typed Kubernetes objects objects, err := io.ParseFile(\"manifests/deployment.yaml\") // Parse YAML bytes directly objects, err := io.ParseYAML(yamlData) Unstructured Fallback By default, only GVKs registered in the kure scheme are accepted. To parse arbitrary Kubernetes YAML (CRDs, custom operators, etc.) use ParseYAMLWithOptions or ParseFileWithOptions with AllowUnstructured:\nopts := io.ParseOptions{AllowUnstructured: true} objects, err := io.ParseYAMLWithOptions(yamlData, opts) // Known types are returned as typed objects (e.g. *corev1.Pod). // Unknown types are returned as *unstructured.Unstructured. Load and Save // Load a single object from file obj, err := io.LoadFile(\"service.yaml\") // Save an object to file err := io.SaveFile(\"output.yaml\", deployment) Serialization Marshal and Unmarshal // Serialize to YAML bytes data, err := io.Marshal(deployment) // Deserialize from YAML bytes var obj appsv1.Deployment err := io.Unmarshal(data, \u0026obj) Encode Multiple Objects // Encode as multi-document YAML yamlData, err := io.EncodeObjectsToYAML(objects) // Encode as JSON array jsonData, err := io.EncodeObjectsToJSON(objects) Deterministic Field Ordering // Encode with Kubernetes-conventional field ordering opts := io.EncodeOptions{KubernetesFieldOrder: true} yamlData, err := io.EncodeObjectsToYAMLWithOptions(objects, opts) // Output: apiVersion, kind, metadata, spec, ... status (last) Server-Set Field Stripping By default, encoding strips server-managed metadata fields that should not appear in client-generated manifests: managedFields, resourceVersion, uid, generation, selfLink, the kubectl.kubernetes.io/last-applied-configuration annotation, null creationTimestamp, and empty status.\n// Default behavior — full stripping (zero value of ServerFieldStripping) yamlData, err := io.EncodeObjectsToYAML(objects) // Explicit full stripping with field ordering opts := io.EncodeOptions{ KubernetesFieldOrder: true, ServerFieldStripping: io.StripServerFieldsFull, } yamlData, err := io.EncodeObjectsToYAMLWithOptions(objects, opts) // Basic stripping (only null creationTimestamp and empty status) opts := io.EncodeOptions{ ServerFieldStripping: io.StripServerFieldsBasic, } yamlData, err := io.EncodeObjectsToYAMLWithOptions(objects, opts) // No stripping — preserve all fields as-is opts := io.EncodeOptions{ ServerFieldStripping: io.StripServerFieldsNone, } yamlData, err := io.EncodeObjectsToYAMLWithOptions(objects, opts) Printing Output Formats The package supports kubectl-compatible output formats:\nFormat Constant Description YAML OutputFormatYAML Full YAML output JSON OutputFormatJSON Full JSON output Table OutputFormatTable Columnar table view Wide OutputFormatWide Extended table with extra columns Name OutputFormatName Resource names only Usage // Print as YAML to stdout err := io.PrintObjectsAsYAML(objects, os.Stdout) // Print as table err := io.PrintObjectsAsTable(objects, false, false, os.Stdout) // Use ResourcePrinter for configurable output printer := io.NewResourcePrinter(io.PrintOptions{ OutputFormat: io.OutputFormatTable, ShowLabels: true, }) err := printer.Print(objects, os.Stdout) Related Packages errors - Error types for parse failures kubernetes - Scheme registration for type-aware parsing",
    "description": "IO - YAML Serialization and Resource Printing The io package provides utilities for parsing, serializing, and printing Kubernetes resources. It supports multiple output formats including YAML, JSON, and kubectl-compatible table views.\nOverview This package handles the I/O boundary of Kure: reading Kubernetes manifests from files, serializing resources to YAML/JSON, and printing resources in human-readable formats. It integrates with Kure’s registered scheme for type-aware parsing.\nParsing Parse YAML Files import \"github.com/go-kure/kure/pkg/io\" // Parse a multi-document YAML file into typed Kubernetes objects objects, err := io.ParseFile(\"manifests/deployment.yaml\") // Parse YAML bytes directly objects, err := io.ParseYAML(yamlData) Unstructured Fallback By default, only GVKs registered in the kure scheme are accepted. To parse arbitrary Kubernetes YAML (CRDs, custom operators, etc.) use ParseYAMLWithOptions or ParseFileWithOptions with AllowUnstructured:",
    "tags": [],
    "title": "IO",
    "uri": "/api-reference/io/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Errors - Structured Error Handling The errors package provides structured error types with contextual information for Kubernetes resource operations. All Kure packages use this instead of fmt.Errorf.\nOverview Errors in Kure carry context: the type of error, what resource was affected, suggestions for fixing the problem, and the original cause. This makes debugging easier and enables programmatic error handling.\nError Types Type Use Case Key Fields ValidationError Field validation failures Field, Value, ValidValues, Suggestion ResourceError Resource-specific issues Kind, Name, Namespace, Available PatchError Patch operation failures Operation, Path, ResourceName ParseError File/YAML parsing errors Source, Line, Column FileError File system operations Operation, Path ConfigError Configuration problems Source, Field, Value, ValidValues Usage Wrapping Errors import \"github.com/go-kure/kure/pkg/errors\" // Wrap with context if err != nil { return errors.Wrap(err, \"failed to load cluster config\") } // Wrap with formatted message return errors.Wrapf(err, \"resource %s/%s not found\", kind, name) Creating Errors // Simple error return errors.New(\"invalid configuration\") // Formatted error return errors.Errorf(\"unknown generator: %s\", name) Typed Errors // Validation error with suggestion return errors.NewValidationError( \"replicas\", // field \"-1\", // value \"Deployment\", // component []string{\"1\", \"3\"}, // valid values ) // Resource not found return errors.ResourceNotFoundError( \"Deployment\", // resource type \"my-app\", // name \"default\", // namespace []string{\"web-app\", \"api-app\"}, // available resources ) // Patch error return errors.NewPatchError( \"set\", // operation \"spec.replicas\", // path \"my-deployment\", // resource name \"field not found\", // reason originalErr, // cause ) // Parse error with location return errors.NewParseError( \"config.yaml\", // source file \"invalid YAML\", // reason 42, // line 10, // column originalErr, // cause ) // File error return errors.NewFileError(\"read\", \"/path/to/file\", \"permission denied\", originalErr) // Configuration error return errors.NewConfigError( \"mise.toml\", // source \"go\", // field \"1.21\", // value \"version too old\", // reason []string{\"1.23\", \"1.24\"}, // valid values ) Inspecting Errors // Check if error is a Kure error if errors.IsKureError(err) { kErr := errors.GetKureError(err) fmt.Println(kErr.Type()) fmt.Println(kErr.Suggestion()) } // Check specific error type if errors.IsType(err, errors.ErrorTypeValidation) { // Handle validation error } Predefined Errors Common nil-resource errors are predefined for use throughout Kure:\nerrors.ErrNilDeployment errors.ErrNilService errors.ErrNilConfigMap errors.ErrNilSecret errors.ErrNilBundle // ... and more for each resource type File and GVK errors:\nerrors.ErrFileNotFound errors.ErrDirectoryNotFound errors.ErrInvalidPath errors.ErrGVKNotFound errors.ErrGVKNotAllowed errors.ErrNilObject Related Packages All Kure packages import this package for error handling. Never use fmt.Errorf directly.",
    "description": "Errors - Structured Error Handling The errors package provides structured error types with contextual information for Kubernetes resource operations. All Kure packages use this instead of fmt.Errorf.\nOverview Errors in Kure carry context: the type of error, what resource was affected, suggestions for fixing the problem, and the original cause. This makes debugging easier and enables programmatic error handling.\nError Types Type Use Case Key Fields ValidationError Field validation failures Field, Value, ValidValues, Suggestion ResourceError Resource-specific issues Kind, Name, Namespace, Available PatchError Patch operation failures Operation, Path, ResourceName ParseError File/YAML parsing errors Source, Line, Column FileError File system operations Operation, Path ConfigError Configuration problems Source, Field, Value, ValidValues Usage Wrapping Errors import \"github.com/go-kure/kure/pkg/errors\" // Wrap with context if err != nil { return errors.Wrap(err, \"failed to load cluster config\") } // Wrap with formatted message return errors.Wrapf(err, \"resource %s/%s not found\", kind, name) Creating Errors // Simple error return errors.New(\"invalid configuration\") // Formatted error return errors.Errorf(\"unknown generator: %s\", name) Typed Errors // Validation error with suggestion return errors.NewValidationError( \"replicas\", // field \"-1\", // value \"Deployment\", // component []string{\"1\", \"3\"}, // valid values ) // Resource not found return errors.ResourceNotFoundError( \"Deployment\", // resource type \"my-app\", // name \"default\", // namespace []string{\"web-app\", \"api-app\"}, // available resources ) // Patch error return errors.NewPatchError( \"set\", // operation \"spec.replicas\", // path \"my-deployment\", // resource name \"field not found\", // reason originalErr, // cause ) // Parse error with location return errors.NewParseError( \"config.yaml\", // source file \"invalid YAML\", // reason 42, // line 10, // column originalErr, // cause ) // File error return errors.NewFileError(\"read\", \"/path/to/file\", \"permission denied\", originalErr) // Configuration error return errors.NewConfigError( \"mise.toml\", // source \"go\", // field \"1.21\", // value \"version too old\", // reason []string{\"1.23\", \"1.24\"}, // valid values ) Inspecting Errors // Check if error is a Kure error if errors.IsKureError(err) { kErr := errors.GetKureError(err) fmt.Println(kErr.Type()) fmt.Println(kErr.Suggestion()) } // Check specific error type if errors.IsType(err, errors.ErrorTypeValidation) { // Handle validation error } Predefined Errors Common nil-resource errors are predefined for use throughout Kure:",
    "tags": [],
    "title": "Errors",
    "uri": "/api-reference/errors/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "CLI - Command-Line Interface Utilities The cli package provides foundational components for Kure’s CLI tools (kure and kurel). It implements the Factory pattern for dependency injection, I/O stream abstraction, and output formatting.\nOverview This package is used internally by the pkg/cmd/ packages to build CLI commands. It provides a clean separation between command logic and I/O handling.\nKey Components Factory Dependency injection container for CLI commands. Provides access to global options, I/O streams, and configuration.\nimport \"github.com/go-kure/kure/pkg/cli\" factory := cli.NewFactory(globalOpts) streams := factory.IOStreams() IOStreams Standard I/O stream abstraction for testable CLI commands:\n// Default streams (stdin/stdout/stderr) streams := cli.NewIOStreams() // Use in commands fmt.Fprintln(streams.Out, \"output\") fmt.Fprintln(streams.ErrOut, \"error\") Fields:\nIn io.Reader - Standard input Out io.Writer - Standard output ErrOut io.Writer - Standard error Printer Output formatting for CLI commands with support for text, YAML, and JSON formats:\nprinter := cli.NewPrinter(cli.PrintOptions{ Format: \"yaml\", }) Config Configuration file handling for CLI tools:\nconfig, err := cli.LoadConfig(\"~/.kure/config.yaml\") Related Packages pkg/cmd/kure - kure CLI command implementation pkg/cmd/kurel - kurel CLI command implementation io - Resource printing and serialization",
    "description": "CLI - Command-Line Interface Utilities The cli package provides foundational components for Kure’s CLI tools (kure and kurel). It implements the Factory pattern for dependency injection, I/O stream abstraction, and output formatting.\nOverview This package is used internally by the pkg/cmd/ packages to build CLI commands. It provides a clean separation between command logic and I/O handling.\nKey Components Factory Dependency injection container for CLI commands. Provides access to global options, I/O streams, and configuration.",
    "tags": [],
    "title": "CLI Utilities",
    "uri": "/api-reference/cli/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Kubernetes Builders - Core Resource Helpers The kubernetes package provides GVK utilities, scheme registration, and strongly-typed builder functions for core Kubernetes resources.\nOverview This package exposes helpers that other Kure packages (and external consumers such as Crane) use to construct and inspect Kubernetes objects without dealing with low-level struct details.\nImport import \"github.com/go-kure/kure/pkg/kubernetes\" GVK Utilities // Resolve the GVK of any registered runtime.Object gvk, err := kubernetes.GetGroupVersionKind(myDeployment) // Check if a GVK is in an allow list ok := kubernetes.IsGVKAllowed(gvk, allowedGVKs) Scheme Registration // Lazily registers all supported API groups (core K8s, FluxCD, cert-manager, etc.) err := kubernetes.RegisterSchemes() HPA Builders // Create a HorizontalPodAutoscaler hpa := kubernetes.CreateHorizontalPodAutoscaler(\"my-app\", \"default\") // Set the scale target err := kubernetes.SetHPAScaleTargetRef(hpa, \"apps/v1\", \"Deployment\", \"my-app\") // Set replica bounds err = kubernetes.SetHPAMinMaxReplicas(hpa, 2, 10) // Add CPU and memory metrics err = kubernetes.AddHPACPUMetric(hpa, 80) err = kubernetes.AddHPAMemoryMetric(hpa, 70) // Set scaling behavior window := int32(300) err = kubernetes.SetHPABehavior(hpa, \u0026autoscalingv2.HorizontalPodAutoscalerBehavior{ ScaleDown: \u0026autoscalingv2.HPAScalingRules{ StabilizationWindowSeconds: \u0026window, }, }) // Update metadata err = kubernetes.SetHPALabels(hpa, map[string]string{\"env\": \"prod\"}) err = kubernetes.SetHPAAnnotations(hpa, map[string]string{\"owner\": \"platform\"}) PDB Builders // Create a PodDisruptionBudget pdb := kubernetes.CreatePodDisruptionBudget(\"my-app\", \"default\") // Set disruption budget (MinAvailable and MaxUnavailable are mutually exclusive) err := kubernetes.SetPDBMinAvailable(pdb, intstr.FromInt32(2)) // or: err = kubernetes.SetPDBMaxUnavailable(pdb, intstr.FromString(\"25%\")) // Set the label selector err = kubernetes.SetPDBSelector(pdb, \u0026metav1.LabelSelector{ MatchLabels: map[string]string{\"app\": \"my-app\"}, }) // Update metadata err = kubernetes.SetPDBLabels(pdb, map[string]string{\"env\": \"prod\"}) err = kubernetes.SetPDBAnnotations(pdb, map[string]string{\"owner\": \"platform\"}) Deployment Builders // Create a Deployment dep := kubernetes.CreateDeployment(\"my-app\", \"default\") // Add a container container := \u0026corev1.Container{Name: \"app\", Image: \"nginx:1.25\"} err := kubernetes.AddDeploymentContainer(dep, container) // Set replicas and strategy err = kubernetes.SetDeploymentReplicas(dep, 3) err = kubernetes.SetDeploymentStrategy(dep, appsv1.DeploymentStrategy{ Type: appsv1.RollingUpdateDeploymentStrategyType, }) // Configure pod template err = kubernetes.SetDeploymentServiceAccountName(dep, \"my-sa\") err = kubernetes.SetDeploymentNodeSelector(dep, map[string]string{\"role\": \"web\"}) err = kubernetes.AddDeploymentToleration(dep, \u0026corev1.Toleration{Key: \"dedicated\", Value: \"web\"}) CronJob Builders // Create a CronJob cj := kubernetes.CreateCronJob(\"my-job\", \"default\", \"*/5 * * * *\") // Add a container container := \u0026corev1.Container{Name: \"worker\", Image: \"busybox:1.36\"} err := kubernetes.AddCronJobContainer(cj, container) // Configure schedule and policies err = kubernetes.SetCronJobConcurrencyPolicy(cj, batchv1.ForbidConcurrent) err = kubernetes.SetCronJobSuccessfulJobsHistoryLimit(cj, 3) err = kubernetes.SetCronJobFailedJobsHistoryLimit(cj, 1) // Configure pod template err = kubernetes.SetCronJobServiceAccountName(cj, \"my-sa\") err = kubernetes.SetCronJobNodeSelector(cj, map[string]string{\"role\": \"batch\"}) err = kubernetes.AddCronJobToleration(cj, \u0026corev1.Toleration{Key: \"dedicated\", Value: \"batch\"}) Service Builders // Create a Service svc := kubernetes.CreateService(\"my-app\", \"default\") // Configure the service err := kubernetes.SetServiceSelector(svc, map[string]string{\"app\": \"my-app\"}) err = kubernetes.AddServicePort(svc, corev1.ServicePort{ Name: \"http\", Port: 80, TargetPort: intstr.FromInt32(8080), }) err = kubernetes.SetServiceType(svc, corev1.ServiceTypeLoadBalancer) // Update metadata err = kubernetes.AddServiceLabel(svc, \"env\", \"prod\") err = kubernetes.AddServiceAnnotation(svc, \"external-dns.alpha.kubernetes.io/hostname\", \"app.example.com\") Ingress Builders // Create an Ingress ing := kubernetes.CreateIngress(\"my-app\", \"default\", \"nginx\") // Build a rule with paths rule := kubernetes.CreateIngressRule(\"app.example.com\") pt := netv1.PathTypePrefix path := kubernetes.CreateIngressPath(\"/\", \u0026pt, \"my-app\", \"http\") kubernetes.AddIngressRulePath(rule, path) err := kubernetes.AddIngressRule(ing, rule) // Add TLS err = kubernetes.AddIngressTLS(ing, netv1.IngressTLS{ Hosts: []string{\"app.example.com\"}, SecretName: \"my-app-tls\", }) Related Packages fluxcd - FluxCD resource constructors errors - Structured error types used for nil-check sentinels",
    "description": "Kubernetes Builders - Core Resource Helpers The kubernetes package provides GVK utilities, scheme registration, and strongly-typed builder functions for core Kubernetes resources.\nOverview This package exposes helpers that other Kure packages (and external consumers such as Crane) use to construct and inspect Kubernetes objects without dealing with low-level struct details.\nImport import \"github.com/go-kure/kure/pkg/kubernetes\" GVK Utilities // Resolve the GVK of any registered runtime.Object gvk, err := kubernetes.GetGroupVersionKind(myDeployment) // Check if a GVK is in an allow list ok := kubernetes.IsGVKAllowed(gvk, allowedGVKs) Scheme Registration // Lazily registers all supported API groups (core K8s, FluxCD, cert-manager, etc.) err := kubernetes.RegisterSchemes() HPA Builders // Create a HorizontalPodAutoscaler hpa := kubernetes.CreateHorizontalPodAutoscaler(\"my-app\", \"default\") // Set the scale target err := kubernetes.SetHPAScaleTargetRef(hpa, \"apps/v1\", \"Deployment\", \"my-app\") // Set replica bounds err = kubernetes.SetHPAMinMaxReplicas(hpa, 2, 10) // Add CPU and memory metrics err = kubernetes.AddHPACPUMetric(hpa, 80) err = kubernetes.AddHPAMemoryMetric(hpa, 70) // Set scaling behavior window := int32(300) err = kubernetes.SetHPABehavior(hpa, \u0026autoscalingv2.HorizontalPodAutoscalerBehavior{ ScaleDown: \u0026autoscalingv2.HPAScalingRules{ StabilizationWindowSeconds: \u0026window, }, }) // Update metadata err = kubernetes.SetHPALabels(hpa, map[string]string{\"env\": \"prod\"}) err = kubernetes.SetHPAAnnotations(hpa, map[string]string{\"owner\": \"platform\"}) PDB Builders // Create a PodDisruptionBudget pdb := kubernetes.CreatePodDisruptionBudget(\"my-app\", \"default\") // Set disruption budget (MinAvailable and MaxUnavailable are mutually exclusive) err := kubernetes.SetPDBMinAvailable(pdb, intstr.FromInt32(2)) // or: err = kubernetes.SetPDBMaxUnavailable(pdb, intstr.FromString(\"25%\")) // Set the label selector err = kubernetes.SetPDBSelector(pdb, \u0026metav1.LabelSelector{ MatchLabels: map[string]string{\"app\": \"my-app\"}, }) // Update metadata err = kubernetes.SetPDBLabels(pdb, map[string]string{\"env\": \"prod\"}) err = kubernetes.SetPDBAnnotations(pdb, map[string]string{\"owner\": \"platform\"}) Deployment Builders // Create a Deployment dep := kubernetes.CreateDeployment(\"my-app\", \"default\") // Add a container container := \u0026corev1.Container{Name: \"app\", Image: \"nginx:1.25\"} err := kubernetes.AddDeploymentContainer(dep, container) // Set replicas and strategy err = kubernetes.SetDeploymentReplicas(dep, 3) err = kubernetes.SetDeploymentStrategy(dep, appsv1.DeploymentStrategy{ Type: appsv1.RollingUpdateDeploymentStrategyType, }) // Configure pod template err = kubernetes.SetDeploymentServiceAccountName(dep, \"my-sa\") err = kubernetes.SetDeploymentNodeSelector(dep, map[string]string{\"role\": \"web\"}) err = kubernetes.AddDeploymentToleration(dep, \u0026corev1.Toleration{Key: \"dedicated\", Value: \"web\"}) CronJob Builders // Create a CronJob cj := kubernetes.CreateCronJob(\"my-job\", \"default\", \"*/5 * * * *\") // Add a container container := \u0026corev1.Container{Name: \"worker\", Image: \"busybox:1.36\"} err := kubernetes.AddCronJobContainer(cj, container) // Configure schedule and policies err = kubernetes.SetCronJobConcurrencyPolicy(cj, batchv1.ForbidConcurrent) err = kubernetes.SetCronJobSuccessfulJobsHistoryLimit(cj, 3) err = kubernetes.SetCronJobFailedJobsHistoryLimit(cj, 1) // Configure pod template err = kubernetes.SetCronJobServiceAccountName(cj, \"my-sa\") err = kubernetes.SetCronJobNodeSelector(cj, map[string]string{\"role\": \"batch\"}) err = kubernetes.AddCronJobToleration(cj, \u0026corev1.Toleration{Key: \"dedicated\", Value: \"batch\"}) Service Builders // Create a Service svc := kubernetes.CreateService(\"my-app\", \"default\") // Configure the service err := kubernetes.SetServiceSelector(svc, map[string]string{\"app\": \"my-app\"}) err = kubernetes.AddServicePort(svc, corev1.ServicePort{ Name: \"http\", Port: 80, TargetPort: intstr.FromInt32(8080), }) err = kubernetes.SetServiceType(svc, corev1.ServiceTypeLoadBalancer) // Update metadata err = kubernetes.AddServiceLabel(svc, \"env\", \"prod\") err = kubernetes.AddServiceAnnotation(svc, \"external-dns.alpha.kubernetes.io/hostname\", \"app.example.com\") Ingress Builders // Create an Ingress ing := kubernetes.CreateIngress(\"my-app\", \"default\", \"nginx\") // Build a rule with paths rule := kubernetes.CreateIngressRule(\"app.example.com\") pt := netv1.PathTypePrefix path := kubernetes.CreateIngressPath(\"/\", \u0026pt, \"my-app\", \"http\") kubernetes.AddIngressRulePath(rule, path) err := kubernetes.AddIngressRule(ing, rule) // Add TLS err = kubernetes.AddIngressTLS(ing, netv1.IngressTLS{ Hosts: []string{\"app.example.com\"}, SecretName: \"my-app-tls\", }) Related Packages fluxcd - FluxCD resource constructors errors - Structured error types used for nil-check sentinels",
    "tags": [],
    "title": "Kubernetes Builders",
    "uri": "/api-reference/kubernetes-builders/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "FluxCD Builders - Flux Resource Constructors The fluxcd package provides strongly-typed constructor functions for creating FluxCD Kubernetes resources. These are the low-level building blocks used by Kure’s higher-level stack and workflow packages.\nOverview Each function takes a configuration struct and returns a fully initialized Flux custom resource. The builders handle API version and kind metadata, letting you focus on the resource specification.\nSupported Resources Source Controllers import \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" // Git repository source gitRepo := fluxcd.GitRepository(\u0026fluxcd.GitRepositoryConfig{ Name: \"my-repo\", Namespace: \"flux-system\", URL: \"https://github.com/org/repo\", Branch: \"main\", Interval: \"5m\", }) // OCI repository source ociRepo := fluxcd.OCIRepository(\u0026fluxcd.OCIRepositoryConfig{ Name: \"my-oci\", Namespace: \"flux-system\", URL: \"oci://registry.example.com/manifests\", Tag: \"latest\", Interval: \"10m\", }) // Helm repository helmRepo := fluxcd.HelmRepository(\u0026fluxcd.HelmRepositoryConfig{ Name: \"bitnami\", Namespace: \"flux-system\", URL: \"https://charts.bitnami.com/bitnami\", Interval: \"1h\", }) // Bucket source bucket := fluxcd.Bucket(\u0026fluxcd.BucketConfig{ Name: \"my-bucket\", Namespace: \"flux-system\", Endpoint: \"minio.example.com\", BucketName: \"manifests\", }) Deployment Controllers // Kustomization (reconciles manifests from a source) ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production/apps\", Interval: \"10m\", Prune: true, SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"my-repo\", }, }) // HelmRelease (reconciles a Helm chart) hr := fluxcd.HelmRelease(\u0026fluxcd.HelmReleaseConfig{ Name: \"redis\", Namespace: \"default\", Chart: \"redis\", Version: \"17.0.0\", RepoName: \"bitnami\", RepoNamespace: \"flux-system\", Values: map[string]interface{}{ \"auth\": map[string]interface{}{ \"enabled\": false, }, }, }) Notification Controllers // Alert alert := fluxcd.Alert(\u0026fluxcd.AlertConfig{ Name: \"slack-alert\", Namespace: \"flux-system\", Provider: \"slack\", Severity: \"error\", }) // Provider provider := fluxcd.Provider(\u0026fluxcd.ProviderConfig{ Name: \"slack\", Namespace: \"flux-system\", Type: \"slack\", Channel: \"#alerts\", }) // Receiver (for webhooks) receiver := fluxcd.Receiver(\u0026fluxcd.ReceiverConfig{ Name: \"github-receiver\", Namespace: \"flux-system\", Type: \"github\", }) Flux Operator // FluxInstance (for flux-operator deployments) instance := fluxcd.FluxInstance(\u0026fluxcd.FluxInstanceConfig{ Name: \"flux\", Namespace: \"flux-system\", }) Modifier Functions Update existing resources:\n// Update Kustomization spec err := fluxcd.SetKustomizationSpec(ks, newSpec) // Update HelmRelease spec err := fluxcd.SetHelmReleaseSpec(hr, newSpec) // Add dependency to Kustomization err := fluxcd.AddKustomizationDependency(ks, kustv1.Dependency{ Name: \"cert-manager\", }) Related Packages stack/fluxcd - High-level Flux workflow engine stack - Domain model that produces Flux resources",
    "description": "FluxCD Builders - Flux Resource Constructors The fluxcd package provides strongly-typed constructor functions for creating FluxCD Kubernetes resources. These are the low-level building blocks used by Kure’s higher-level stack and workflow packages.\nOverview Each function takes a configuration struct and returns a fully initialized Flux custom resource. The builders handle API version and kind metadata, letting you focus on the resource specification.\nSupported Resources Source Controllers import \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" // Git repository source gitRepo := fluxcd.GitRepository(\u0026fluxcd.GitRepositoryConfig{ Name: \"my-repo\", Namespace: \"flux-system\", URL: \"https://github.com/org/repo\", Branch: \"main\", Interval: \"5m\", }) // OCI repository source ociRepo := fluxcd.OCIRepository(\u0026fluxcd.OCIRepositoryConfig{ Name: \"my-oci\", Namespace: \"flux-system\", URL: \"oci://registry.example.com/manifests\", Tag: \"latest\", Interval: \"10m\", }) // Helm repository helmRepo := fluxcd.HelmRepository(\u0026fluxcd.HelmRepositoryConfig{ Name: \"bitnami\", Namespace: \"flux-system\", URL: \"https://charts.bitnami.com/bitnami\", Interval: \"1h\", }) // Bucket source bucket := fluxcd.Bucket(\u0026fluxcd.BucketConfig{ Name: \"my-bucket\", Namespace: \"flux-system\", Endpoint: \"minio.example.com\", BucketName: \"manifests\", }) Deployment Controllers // Kustomization (reconciles manifests from a source) ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"flux-system\", Path: \"./clusters/production/apps\", Interval: \"10m\", Prune: true, SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"my-repo\", }, }) // HelmRelease (reconciles a Helm chart) hr := fluxcd.HelmRelease(\u0026fluxcd.HelmReleaseConfig{ Name: \"redis\", Namespace: \"default\", Chart: \"redis\", Version: \"17.0.0\", RepoName: \"bitnami\", RepoNamespace: \"flux-system\", Values: map[string]interface{}{ \"auth\": map[string]interface{}{ \"enabled\": false, }, }, }) Notification Controllers // Alert alert := fluxcd.Alert(\u0026fluxcd.AlertConfig{ Name: \"slack-alert\", Namespace: \"flux-system\", Provider: \"slack\", Severity: \"error\", }) // Provider provider := fluxcd.Provider(\u0026fluxcd.ProviderConfig{ Name: \"slack\", Namespace: \"flux-system\", Type: \"slack\", Channel: \"#alerts\", }) // Receiver (for webhooks) receiver := fluxcd.Receiver(\u0026fluxcd.ReceiverConfig{ Name: \"github-receiver\", Namespace: \"flux-system\", Type: \"github\", }) Flux Operator // FluxInstance (for flux-operator deployments) instance := fluxcd.FluxInstance(\u0026fluxcd.FluxInstanceConfig{ Name: \"flux\", Namespace: \"flux-system\", }) Modifier Functions Update existing resources:",
    "tags": [],
    "title": "FluxCD Builders",
    "uri": "/api-reference/fluxcd-builders/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Logger - Logging Utilities The logger package provides structured logging for Kure. All logging in the project should use this package instead of fmt.Print or the standard log package.\nOverview The logger provides a simple interface for structured key-value logging with support for different log levels. It wraps an underlying structured logger and provides convenience functions.\nUsage import \"github.com/go-kure/kure/pkg/logger\" // Default logger log := logger.Default() // Log with context log.Info(\"loading package\", \"path\", \"/path/to/package\") log.Error(\"failed to parse\", \"error\", err, \"file\", \"config.yaml\") // No-op logger (for quiet mode) log := logger.Noop() Log Levels Level Usage Info Normal operational messages Error Error conditions Debug Detailed debugging information Warn Warning conditions Conventions Use key-value pairs for structured data: log.Info(\"msg\", \"key1\", val1, \"key2\", val2) Use logger.Noop() when verbose output is disabled Pass the logger through function parameters or options structs Use logger.Default() only at initialization points (CLI entry, tests) Related Packages All Kure packages use this logger. See the errors package for error handling patterns.",
    "description": "Logger - Logging Utilities The logger package provides structured logging for Kure. All logging in the project should use this package instead of fmt.Print or the standard log package.\nOverview The logger provides a simple interface for structured key-value logging with support for different log levels. It wraps an underlying structured logger and provides convenience functions.\nUsage import \"github.com/go-kure/kure/pkg/logger\" // Default logger log := logger.Default() // Log with context log.Info(\"loading package\", \"path\", \"/path/to/package\") log.Error(\"failed to parse\", \"error\", err, \"file\", \"config.yaml\") // No-op logger (for quiet mode) log := logger.Noop() Log Levels Level Usage Info Normal operational messages Error Error conditions Debug Detailed debugging information Warn Warning conditions Conventions Use key-value pairs for structured data: log.Info(\"msg\", \"key1\", val1, \"key2\", val2) Use logger.Noop() when verbose output is disabled Pass the logger through function parameters or options structs Use logger.Default() only at initialization points (CLI entry, tests) Related Packages All Kure packages use this logger. See the errors package for error handling patterns.",
    "tags": [],
    "title": "Logger",
    "uri": "/api-reference/logger/index.html"
  },
  {
    "breadcrumb": "Go Kure \u003e API Reference",
    "content": "Kure Compatibility Matrix This document describes the versions of infrastructure tools that Kure supports.\nVersion Philosophy Kure maintains two version concepts for each dependency:\nBuild Version (current in versions.yaml): The exact library version Kure imports in go.mod Deployment Compatibility (supported_range): The range of deployed tool versions that Kure can generate YAML for Go Version Current: Go 1.24.12\nInfrastructure Dependencies Tool Build Version Deployment Compatibility Notes cert-manager 1.16.5 1.14 - 1.16 1.17+ requires Go 1.25 fluxcd 2.6.4 2.4 - 2.6 2.7+ requires Go 1.25, tracked in #128 image-automation-controller 1.0+ requires Go 1.25 (#171) All github.com/fluxcd/* packages blocked from minor/major updates flux-operator 0.24.1 0.23 - 0.24 0.25+ requires Go 1.25 metallb 0.15.2 0.14 - 0.15 0.15.3+ requires Go 1.25 and triggers k8s.io upgrade to 0.34+ (#169) external-secrets 0.19.2 0.18 - 0.19 Compatible with current Go version controller-runtime 0.21.0 0.19 - 0.21 0.22+ requires Go 1.25 kubernetes 0.33.2 1.28 - 1.33 Tested in CI matrix Understanding the Matrix Build Version (go.mod) The version Kure imports and builds against. This is validated by CI to match versions.yaml.\nDeployment Compatibility The range of versions that Kure can generate valid YAML for. Kure may generate YAML compatible with older or newer versions than it builds against.\nFor example:\nKure builds against cert-manager 1.16.2 But generates YAML compatible with cert-manager 1.14.x, 1.15.x, and 1.16.x Upgrading Dependencies When upgrading a dependency:\nUpdate versions.yaml with new current and supported_range Run go get \u003cmodule\u003e@\u003cversion\u003e to update go.mod Update code for any API changes Run ./scripts/sync-versions.sh generate to update docs Run ./scripts/sync-versions.sh check to validate consistency Related Issues #133 - Go 1.25 upgrade tracking #128 - FluxCD ecosystem upgrade (blocked by Go 1.25)",
    "description": "Kure Compatibility Matrix This document describes the versions of infrastructure tools that Kure supports.\nVersion Philosophy Kure maintains two version concepts for each dependency:\nBuild Version (current in versions.yaml): The exact library version Kure imports in go.mod Deployment Compatibility (supported_range): The range of deployed tool versions that Kure can generate YAML for Go Version Current: Go 1.24.12\nInfrastructure Dependencies Tool Build Version Deployment Compatibility Notes cert-manager 1.16.5 1.14 - 1.16 1.17+ requires Go 1.25 fluxcd 2.6.4 2.4 - 2.6 2.7+ requires Go 1.25, tracked in #128 image-automation-controller 1.0+ requires Go 1.25 (#171) All github.com/fluxcd/* packages blocked from minor/major updates flux-operator 0.24.1 0.23 - 0.24 0.25+ requires Go 1.25 metallb 0.15.2 0.14 - 0.15 0.15.3+ requires Go 1.25 and triggers k8s.io upgrade to 0.34+ (#169) external-secrets 0.19.2 0.18 - 0.19 Compatible with current Go version controller-runtime 0.21.0 0.19 - 0.21 0.22+ requires Go 1.25 kubernetes 0.33.2 1.28 - 1.33 Tested in CI matrix Understanding the Matrix Build Version (go.mod) The version Kure imports and builds against. This is validated by CI to match versions.yaml.",
    "tags": [],
    "title": "Compatibility Matrix",
    "uri": "/api-reference/compatibility/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Kure: Type-Safe Kubernetes Resource Generation Warning Work in Progress: Kure is currently under active development (v0.1.0-alpha.2). APIs and features are subject to change. Kure is a Go library for programmatically building Kubernetes resources, designed for GitOps workflows with FluxCD. Instead of complex templating engines, Kure provides strongly-typed, composable resource generation in native Go.\nWhy Kure? Building Kubernetes manifests for GitOps can be challenging:\nYAML templating is error-prone and hard to maintain Helm charts add complexity with their templating language Raw manifests lead to duplication and inconsistency Kure solves these problems by providing:\nType-safe builders that catch errors at compile time Composable patterns for reusable resource generation Native Go code instead of template syntax GitOps-ready output for Flux Quick Example import ( \"os\" \"github.com/go-kure/kure/pkg/kubernetes/fluxcd\" \"github.com/go-kure/kure/pkg/io\" kustv1 \"github.com/fluxcd/kustomize-controller/api/v1\" ) // Create a Flux Kustomization ks := fluxcd.Kustomization(\u0026fluxcd.KustomizationConfig{ Name: \"my-app\", Namespace: \"default\", Path: \"./manifests\", Interval: \"5m\", SourceRef: kustv1.CrossNamespaceSourceReference{ Kind: \"GitRepository\", Name: \"my-repo\", }, }) // Output as YAML io.Marshal(os.Stdout, ks) Features Comprehensive Resource Support: Core Kubernetes, FluxCD, cert-manager, External Secrets, MetalLB Hierarchical Organization: Cluster, Node, Bundle, Application structure for clean GitOps layouts Declarative Patching: JSONPath-based patching system for resource customization Kurel Package System: Reusable application packages with patch-based customization ArgoCD support is planned but not yet production-ready.\nLearn More Getting Started - Installation and quickstart guide Concepts - Architecture and design philosophy Guides - How-to guides for common workflows Examples - See Kure in action API Reference - Package documentation Get Involved Kure is open source and welcomes contributions!\nGitHub Repository Issue Tracker Discussions",
    "description": "Kure: Type-Safe Kubernetes Resource Generation Warning Work in Progress: Kure is currently under active development (v0.1.0-alpha.2). APIs and features are subject to change. Kure is a Go library for programmatically building Kubernetes resources, designed for GitOps workflows with FluxCD. Instead of complex templating engines, Kure provides strongly-typed, composable resource generation in native Go.\nWhy Kure? Building Kubernetes manifests for GitOps can be challenging:",
    "tags": [],
    "title": "Go Kure",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "Go Kure",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
